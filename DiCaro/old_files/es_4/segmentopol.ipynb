{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impementazione dell'esercizio sulla test segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step algoritmo:\n",
    "\n",
    "- Dividere il file per righe, le righe guideranno l'esercizio in quanto ai tali ci sarà associata la riga di riferimento;\n",
    "- Contare il valore di co-occorrenza per ogni frase:\n",
    "  - Il valore di co-occorrenza è la somma dei valori di co-occorrenza per ogni parola in una frase;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagli corretti (ita)\n",
    "* 36/37 - taglio arg 1/2\n",
    "* 56/57 - taglio arg 2/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagli corretti (en)\n",
    "\n",
    "- 59/60\n",
    "- 102/103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from gensim.test.utils import simple_preprocess\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim import models\n",
    "from pprint import pprint\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words_ita(phrase):\n",
    "    stop_words = stopwords.words('italian')\n",
    "    phrase = phrase.split()\n",
    "    phrase = [word for word in phrase if word not in stop_words]\n",
    "    return phrase\n",
    "\n",
    "def get_text_from_file(path):\n",
    "    file = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    with open (path, 'r') as f:\n",
    "        for row in f:\n",
    "            filtered_s = [w for w in word_tokenize(row) if not w.lower() in stop_words]\n",
    "            file.append(simple_preprocess(str(filtered_s), deacc=True))\n",
    "    f.close()\n",
    "    return file\n",
    "\n",
    "def cooccurrence(text):\n",
    "    '''\n",
    "    Calculates the cooccurrence value of a sequence of words. \n",
    "    This value correspond to the sum of the occurrences of the n most frequently used words in the word list.\n",
    "    '''\n",
    "    score = 0\n",
    "    c = Counter()\n",
    "    most_common = []\n",
    "    for row in text:\n",
    "        c.update(row)\n",
    "        \n",
    "    most_common = c.most_common(3)\n",
    "    # print(most_common)\n",
    "    \n",
    "    for el in most_common:\n",
    "        score = score + el[1]\n",
    "        \n",
    "    return score\n",
    "\n",
    "def extract_segment(file, start, end):\n",
    "    '''\n",
    "    Given the first and the last line, extract the segment.\n",
    "    '''\n",
    "    segment = []\n",
    "    for i in range(start, end):\n",
    "        segment.append(file[i])\n",
    "    return segment\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organizziamo le parole in una lista di liste, in qui ogni lista corrisponderà alle parole di una riga tokenizzate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('quantum', 63), ('gorilla', 34), ('gorillas', 31), ('astronomy', 25), ('also', 17), ('classical', 17), ('algorithm', 16), ('stars', 16), ('silverback', 15), ('astronomical', 15), ('ray', 15), ('females', 14), ('computers', 14), ('computer', 14), ('wavelengths', 14), ('males', 13), ('known', 13), ('model', 13), ('algorithms', 13), ('early', 13), ('earth', 13), ('light', 13), ('infrared', 13), ('male', 12), ('problems', 12), ('planets', 12), ('western', 11), ('ft', 11), ('may', 11), ('made', 11)]\n"
     ]
    }
   ],
   "source": [
    "file = get_text_from_file('../res/segmentation_eng.txt')\n",
    "c = Counter()\n",
    "num_lines = sum(1 for line in open('../res/segmentation_eng.txt')) # Number of lines in the file\n",
    "\n",
    "for row in file:\n",
    "    c.update(row)\n",
    "    \n",
    "print(c.most_common(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramethers tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcolo dei valori standard per i tagli iniziali, per farlo divido il totale delle linee per il numero di topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 60, 120, 181]\n"
     ]
    }
   ],
   "source": [
    "cut = []\n",
    "n_topic = 3\n",
    "\n",
    "cut.append(0)\n",
    "for k in range(1, n_topic):\n",
    "    cut.append(num_lines // n_topic * k)\n",
    "cut.append(num_lines)\n",
    "\n",
    "print(cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcolo il valore di cooccorrenza per ogni segmento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "45\n",
      "[7, 64, 105]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "cut = [0 , 3, 45, num_lines]\n",
    "# Extract the segments\n",
    "for i in range(len(cut)-1):\n",
    "    print(cut[i])\n",
    "    text = extract_segment(file, cut[i], cut[i+1])\n",
    "    scores.append(cooccurrence(text))\n",
    "    \n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First implementation of the complete algorithm - DIDN'T WORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_scores, scores = [0, 0, 0], [0, 0, 0]\n",
    "sum_score = 0\n",
    "max = 0\n",
    "# cut = [0, 10, 45, num_lines]\n",
    "\n",
    "#* Questi parametri sono legati alle singole iterazioni, quindi alla ricerca dei tagli legati ai singoli segmenti\n",
    "limit = [0, 0, 0] # Used to avoid to go to far away from the cut\n",
    "direction = [1, 1, 1] # Indicate the direction of the search, 1 mean \"top\" and -1 mean \"bottom\"\n",
    "\n",
    "cut = [0, 40, 120, num_lines] #* Real: [59, 102]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prendiamo la somma di tutti gli score (dei 3 segmenti) e cerchiamo di massimizzarla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/paolobonicco/virtual-envs/tln-2022-third-part-lab/es4_segmentation/segmentopol.ipynb Cell 20'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/paolobonicco/virtual-envs/tln-2022-third-part-lab/es4_segmentation/segmentopol.ipynb#ch0000019?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(cut)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/paolobonicco/virtual-envs/tln-2022-third-part-lab/es4_segmentation/segmentopol.ipynb#ch0000019?line=4'>5</a>\u001b[0m     text \u001b[39m=\u001b[39m extract_segment(file, cut[i], cut[i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/paolobonicco/virtual-envs/tln-2022-third-part-lab/es4_segmentation/segmentopol.ipynb#ch0000019?line=5'>6</a>\u001b[0m     scores[i] \u001b[39m=\u001b[39m cooccurrence(text)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/paolobonicco/virtual-envs/tln-2022-third-part-lab/es4_segmentation/segmentopol.ipynb#ch0000019?line=7'>8</a>\u001b[0m sum_scores \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(scores)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/paolobonicco/virtual-envs/tln-2022-third-part-lab/es4_segmentation/segmentopol.ipynb#ch0000019?line=8'>9</a>\u001b[0m \u001b[39mif\u001b[39;00m(sum_scores \u001b[39m>\u001b[39m \u001b[39mmax\u001b[39m):\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "# Extract the segments\n",
    "for f in range(2000):    \n",
    "    \n",
    "    for i in range(len(cut)-1):\n",
    "        text = extract_segment(file, cut[i], cut[i+1])\n",
    "        scores[i] = cooccurrence(text)\n",
    "        \n",
    "    sum_scores = sum(scores)\n",
    "    if(sum_scores > max):\n",
    "        max = sum_scores\n",
    "    \n",
    "    # Check the score and update the max for each segment\n",
    "    for k in range(len(cut)-1):\n",
    "        \n",
    "        # Find the cut for the first segments wich is special because have just 1 boundary\n",
    "        if k == 0:\n",
    "            if(scores[k] > max_scores[k]):\n",
    "                max_scores[k] = scores[k]\n",
    "                limit[k] = 0\n",
    "            # Update the value of cut --> Try a direction\n",
    "            elif limit[k] < 5:\n",
    "                cut[1] = cut[1] + (1 * direction[k])\n",
    "                limit[k] = limit[k] + 1\n",
    "            # Change direction of search --> Wrong direction\n",
    "            else:\n",
    "                cut[k] =  cut[k] - (limit[k] * -direction[k])\n",
    "                direction[k] *= -1\n",
    "                limit[k] = 0\n",
    "        else:     \n",
    "            if scores[k] > max_scores[k]:\n",
    "                max_scores[k] = scores[k]\n",
    "                limit[k] = 0\n",
    "            elif limit[k] < 5:\n",
    "                cut[k] = cut[k] + (1 * direction[k])\n",
    "                limit[k] = limit[k] + 1\n",
    "            else: # Update the cut point\n",
    "                direction[k] = direction[k] * -1\n",
    "                limit[k] = 0\n",
    "                cut[k] = cut[k] + (1 * direction[k])\n",
    "        \n",
    "# print(scores)\n",
    "\n",
    "print(f'\\n The Max values is {max_scores} at lines {cut}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second implementation of the complete algorithm: Maximise the sum of the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best cut at lines \n",
      "[0, 59, 102, 181]\n",
      " the max sum is \n",
      "231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract the segments\n",
    "x , y, max = 0, 0, 0\n",
    "max_scores = [(0, 0), (0, 0), (0, 0)]\n",
    "max_cut = []\n",
    "scores = [0, 0, 0]\n",
    "\n",
    "for f in range(20000): \n",
    "    \n",
    "    y = random.randint(2, num_lines-1)\n",
    "    x = random.randint(1, num_lines-2)\n",
    "    \n",
    "    while x > y:\n",
    "        y = random.randint(2, num_lines-1)\n",
    "        x = random.randint(1, num_lines-2)\n",
    "    \n",
    "    cut = [0, x, y, num_lines]\n",
    "    \n",
    "    for i in range(len(cut)-1):\n",
    "        text = extract_segment(file, cut[i], cut[i+1])\n",
    "        scores[i] = cooccurrence(text)\n",
    "        \n",
    "    sum_scores = sum(scores)\n",
    "    if(sum_scores > max):\n",
    "        max = sum_scores\n",
    "        max_cut = cut\n",
    "    \n",
    "    for d in range(len(scores)):\n",
    "        max_scores[d] = (cut[d], scores[d])\n",
    "        \n",
    "        \n",
    "# print(scores)\n",
    "\n",
    "print(f'\\n Best cut at lines \\n{max_cut}\\n the max sum is \\n{max}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best cut for first segment - Funziona solo con un punto di partenza inferiore al toglio corretto (59) in quanto non c'è un limite \"destro\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The Max value is: 80 at line 59\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "scores.append(0)\n",
    "max_scores = (0, 0)\n",
    "cut = [0, 10, 45, num_lines]\n",
    "limit = 0 # Used to avoid to go to far away from the cut\n",
    "direction = 1 # Indicate the direction of the search, 1 mean \"top\" and -1 mean \"bottom\"\n",
    "\n",
    "# Extract the segments\n",
    "for f in range(1000):\n",
    "    text = extract_segment(file, cut[0], cut[1])\n",
    "    scores[0] = cooccurrence(text)\n",
    "    \n",
    "    # print(scores)\n",
    "        \n",
    "    # Save the max value and the cut line --> Good value found\n",
    "    if(scores[0] > max_scores[1]):\n",
    "        max_scores = (cut[1], scores[0])\n",
    "        limit = 0\n",
    "        \n",
    "    # Update the value of cut --> Try a direction\n",
    "    elif limit < 5:\n",
    "        cut[1] = cut[1] + (1 * direction)\n",
    "        limit = limit + 1\n",
    "    \n",
    "    # Change direction of search --> Wrong direction\n",
    "    else:\n",
    "        direction *= -1\n",
    "        limit = 0\n",
    "\n",
    "    \n",
    "# print(scores)\n",
    "\n",
    "print(f'\\n The Max value is: {max_scores[1]} at line {max_scores[0]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
