{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/semcor3.0/brown1/tagfiles/br-a01\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "\n",
    "def lesk(word, sentence):\n",
    "    \"\"\"Lesk algorithm implementation. Given a word and a sentence in which it appears,\n",
    "    it returns the best sense of the word.\n",
    "    Args:\n",
    "        word: word to disambiguate\n",
    "        sentence: sentence to compare\n",
    "    Returns:\n",
    "        best sense of word\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculating the synset of the given word inside WN\n",
    "    word_senses = wn.synsets(word)\n",
    "    best_sense = word_senses[0]\n",
    "    max_overlap = 0\n",
    "\n",
    "    # I choose the bag of words approach\n",
    "    context = bag_of_word(sentence)\n",
    "\n",
    "    for sense in word_senses:\n",
    "        # set of words in the gloss\n",
    "        signature = bag_of_word(sense.definition())\n",
    "\n",
    "        # and examples of the given sense\n",
    "        examples = sense.examples()\n",
    "        for ex in examples:\n",
    "            # after this line, signature will contain for all the words, their\n",
    "            # bag of words definition and their examples\n",
    "            signature = signature.union(bag_of_word(ex))\n",
    "\n",
    "        overlap = compute_overlap(signature, context)\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            best_sense = sense\n",
    "\n",
    "    return best_sense\n",
    "\n",
    "\n",
    "def bag_of_word(sent):\n",
    "    \"\"\"Auxiliary function for the Lesk algorithm. Transforms the given sentence\n",
    "    according to the bag of words approach, apply lemmatization, stop words\n",
    "    and punctuation removal.\n",
    "    Args:\n",
    "        sent: sentence\n",
    "    Returns:\n",
    "        bag of words\n",
    "    \"\"\"\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    punctuation = {',', ';', '(', ')', '{', '}', ':', '?', '!'}\n",
    "    # Returns the input word unchanged if it cannot be found in WordNet.\n",
    "    wnl = nltk.WordNetLemmatizer()\n",
    "    # Return a tokenized copy of text, using NLTKâ€™s recommended word tokenizer (Treebank + PunkSentence)\n",
    "    tokens = nltk.word_tokenize(sent)\n",
    "    tokens = list(filter(lambda x: x not in stop_words and x not in punctuation, tokens))\n",
    "    return set(wnl.lemmatize(t) for t in tokens)\n",
    "\n",
    "\n",
    "def compute_overlap(signature, context):\n",
    "    \"\"\"Auxiliary function for the Lesk algorithm. Computes the number of words in\n",
    "    common between signature and context.\n",
    "    Args: \n",
    "        signature: bag of words of the signature (e.g. definitions + examples)\n",
    "        context: bag of words of the context (e.g. sentence)\n",
    "    Returns:\n",
    "        number of elements in commons\n",
    "    \"\"\"\n",
    "\n",
    "    return len(signature & context)\n",
    "\n",
    "\n",
    "def get_sense_index(word, sense):\n",
    "    \"\"\"Given a ambiguous word and a sense of that word, it returns the\n",
    "    corresponding index of the sense in the synsets list associated with the\n",
    "    word indices starts with 1.\n",
    "    Args: \n",
    "        word: ambiguous word (with more that 1 sense)\n",
    "        sense: sense of the word\n",
    "    Returns:\n",
    "        index of the sense in the synsets list of the word\n",
    "    \"\"\"\n",
    "\n",
    "    senses = wn.synsets(word)\n",
    "    return senses.index(sense) + 1\n",
    "\n",
    "\n",
    "def pos_validity(pos, text, word):\n",
    "    \"\"\"Auxiliary function for the parse_xml\n",
    "    Args:\n",
    "        pos:\n",
    "        text:\n",
    "        word: ambiguous word (with more that 1 sense)\n",
    "    Returns:\n",
    "        boolean: True if the word is valid and false otherwise\n",
    "    \"\"\"\n",
    "    return pos == 'NN' and '_' not in text and len(wn.synsets(text)) > 1 and 'wnsn' in word.attrib\n",
    "\n",
    "\n",
    "def max_freq(word):\n",
    "    \"\"\"\n",
    "    Helper method for lesk_demaria\n",
    "    :param word of interest\n",
    "    :return: frequency of the word\n",
    "    \"\"\"\n",
    "    synsets = wn.synsets(word)\n",
    "    sense2freq = None\n",
    "    freq_max = 0\n",
    "\n",
    "    for s in synsets:\n",
    "        freq = 0\n",
    "        for lemma in s.lemmas():\n",
    "            freq += lemma.count()\n",
    "            if freq > freq_max:\n",
    "                freq_max = freq\n",
    "                sense2freq = s\n",
    "    return sense2freq\n",
    "\n",
    "\n",
    "def lesk_demaria(word, sentence):\n",
    "    \"\"\"\n",
    "    Given a word and a sentence in which it appears, it returns the best sense of the word.\n",
    "    DeMaria Implementation more precise than simpler lesk above thanks to max_freq\n",
    "    Args:\n",
    "        word: word to disambiguate\n",
    "        sentence: sentence to compare\n",
    "    Returns:\n",
    "        best sense of word\n",
    "    \"\"\"\n",
    "    # inizializzazione\n",
    "    max_overlap = 0\n",
    "    best_sense = max_freq(word)\n",
    "\n",
    "    # If I choose the bag of words approach\n",
    "    context = bag_of_word(sentence)\n",
    "    signature = []\n",
    "\n",
    "    for ss in wn.synsets(word):\n",
    "        signature += ss.definition().split()\n",
    "        signature += ss.lemma_names()\n",
    "\n",
    "        overlap = set(signature).intersection(context)\n",
    "        signature.clear()\n",
    "\n",
    "        if len(overlap) > max_overlap:\n",
    "            best_sense = ss\n",
    "            max_overlap = len(overlap)\n",
    "\n",
    "    return best_sense"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venvradicioni': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "585c611d1963e3d050f9aad8a09a6992370122bcceddf6a7b91b57ac2b60585c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
