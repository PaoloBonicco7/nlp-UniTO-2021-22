{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Es2 - Word Sense Disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo esercizio andremo ad estrarre 50 frasi causuali dal corpus `SemCor` e proveremo a disambiguare un sostantivo per ogni frase, anche\n",
    "quest'ultimo estratto casualmente dalla frase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Estrazione casuale delle frasi dal corpus `SemCor`\n",
    "2. Pulizia delle frasi:\n",
    "   1. Rimozione stopwords, punteggiatura e lemming\n",
    "3. Estrazione di un sostantivo casuale dalla frase\n",
    "4. Estrazione dei synset del sostantivo **?? (domanda, estraggo solo i sysnet che sono etichettati come *NN*)**\n",
    "5. Costruzione della `Bag of Words` per la frase e del sostantivo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and dataset downlaod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import semcor\n",
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "import random\n",
    "from pprint import pprint\n",
    "from nltk.tree import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('semcor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esempio di frase del corpus e lunghezza totale frasi nel corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "testl = semcor.tagged_sents(tag=\"sem\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The'],\n",
       " Tree(Lemma('group.n.01.group'), [Tree('NE', ['Fulton', 'County', 'Grand', 'Jury'])]),\n",
       " Tree(Lemma('state.v.01.say'), ['said']),\n",
       " Tree(Lemma('friday.n.01.Friday'), ['Friday']),\n",
       " ['an'],\n",
       " Tree(Lemma('probe.n.01.investigation'), ['investigation']),\n",
       " ['of'],\n",
       " Tree(Lemma('atlanta.n.01.Atlanta'), ['Atlanta']),\n",
       " [\"'s\"],\n",
       " Tree(Lemma('late.s.03.recent'), ['recent']),\n",
       " Tree(Lemma('primary.n.01.primary_election'), ['primary', 'election']),\n",
       " Tree(Lemma('produce.v.04.produce'), ['produced']),\n",
       " ['``'],\n",
       " ['no'],\n",
       " Tree(Lemma('evidence.n.01.evidence'), ['evidence']),\n",
       " [\"''\"],\n",
       " ['that'],\n",
       " ['any'],\n",
       " Tree(Lemma('abnormality.n.04.irregularity'), ['irregularities']),\n",
       " Tree(Lemma('happen.v.01.take_place'), ['took', 'place']),\n",
       " ['.']]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', 'Atlanta', \"'s\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n",
      "37176\n"
     ]
    }
   ],
   "source": [
    "sents = semcor.sents()\n",
    "print(sents[0])\n",
    "print(len(sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metodi utili per gestione Corpus `SemCor` e struttura `Tree` di `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postag(word):\n",
    "    '''\n",
    "    Given a word as a Tree, returns the Part of Speech Tag (PoS Tag).\n",
    "    '''\n",
    "    return word.pos()[0][1]\n",
    "\n",
    "def get_walue(word):\n",
    "    '''\n",
    "    Given a word as a Tree, returns the word.\n",
    "    '''\n",
    "    return word.leaves()[0] # word.pos()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('refuse.v.02')"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma = \"refuse.v.02.reject\"\n",
    "wn.lemma(lemma).synset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent:  [Tree('IN', ['Before']), Tree('appeal_to.v.00', [Tree('VB', ['appealing', 'to'])]), Tree('DT', ['the']), Tree('NNP', ['U.', 'N.']), Tree('CC', ['or']), Tree('TO', ['to']), Tree('NNP', ['Russia']), Tree(None, [',']), Tree('PRP', ['he']), Tree('JJ', ['first']), Tree('appeal_to.v.00', [Tree('VB', ['appealed', 'to'])]), Tree('DT', ['the']), Tree('NNP', ['U.', 'S.']), Tree('IN', ['for']), Tree('JJ', ['military']), Tree('NN', ['help']), Tree(None, [',']), Tree('CC', ['and']), Tree('VBD', ['was']), Tree(Lemma('refuse.v.02.reject'), [Tree('VB', ['rejected'])]), Tree(None, ['.']), Tree(None, [')'])]\n",
      "Sent:  [Tree('IN', ['As']), Tree('PRP', ['they']), Tree(Lemma('look.v.01.look'), [Tree('VB', ['looked'])]), Tree('with_nostalgia.r.00', [Tree('RB', ['with', 'nostalgia'])]), Tree('TO', ['to']), Tree('DT', ['a']), Tree(Lemma('society.n.01.society'), [Tree('NN', ['society'])]), Tree('WDT', ['which']), Tree('VBD', ['had']), Tree('VBN', ['been']), Tree(Lemma('wipe_out.v.03.sweep_away'), [Tree('VB', ['swept', 'away'])]), Tree(None, [',']), Tree('PRP', ['they']), Tree(Lemma('be.v.01.be'), [Tree('VB', ['were'])]), Tree(Lemma('probably.r.01.probably'), [Tree('RB', ['probably'])]), Tree(Lemma('no.r.01.no_more'), [Tree('RB', ['no', 'more'])]), Tree('RB', ['than']), Tree(Lemma('half.s.02.half'), [Tree('JJ', ['half'])]), Tree(Lemma('conscious.a.02.conscious'), [Tree('JJ', ['conscious'])]), Tree('IN', ['that']), Tree('PRP', ['they']), Tree('NNS', ['painted', 'in', 'colors']), Tree('WDT', ['which']), Tree('VBD', ['had']), Tree(Lemma('never.r.01.never'), [Tree('RB', ['never'])]), Tree(Lemma('exist.v.01.exist'), [Tree('VB', ['existed'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('IN', ['While']), Tree('RB', ['here']), Tree(None, [',']), Tree(Lemma('visit.v.01.visit'), [Tree('VB', ['visit'])]), Tree('NN', ['Theodore', 'Roosevelt']), Tree('NN', ['National', 'Park']), Tree('IN', ['for']), Tree('PRP$', ['its']), Tree('JJ', ['spectacular']), Tree('NN', ['scenery']), Tree(None, ['.'])]\n",
      "Sent:  [Tree('RB', ['For', 'example']), Tree(None, [',']), Tree('IN', ['if']), Tree('PRP', ['you']), Tree(Lemma('be.v.02.be'), [Tree('VB', ['are'])]), Tree('DT', ['a']), Tree('RB', ['reasonably']), Tree('JJ', ['well-adjusted']), Tree('NN', ['person']), Tree(None, [',']), Tree('EX', ['there']), Tree(Lemma('be.v.01.be'), [Tree('VB', ['are'])]), Tree('JJ', ['certain']), Tree('NNS', ['ways']), Tree('WDT', ['that']), Tree(Lemma('be.v.01.be'), [Tree('VB', ['are'])]), Tree('JJ', ['reasonable']), Tree('CC', ['and']), Tree('JJ', ['appropriate']), Tree('IN', ['for']), Tree(Lemma('address.v.01.address'), [Tree('VB', ['addressing'])]), Tree('PRP$', ['your']), Tree('NN', ['mother']), Tree(None, ['.'])]\n",
      "Sent:  [Tree(Lemma('person.n.01.person'), [Tree('NE', [Tree('NNP', ['Palmer'])])]), Tree('POS', [\"'s\"]), Tree(Lemma('twelve.n.01.dozen'), [Tree('NN', ['dozen'])]), Tree('VBD', ['were']), Tree(Lemma('honestly.r.01.honestly'), [Tree('RB', ['honestly'])]), Tree(Lemma('earn.v.02.earn'), [Tree('VB', ['earned'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('IN', ['Without']), Tree(Lemma('look.v.01.look'), [Tree('VB', ['looking'])]), Tree('VB', ['at']), Tree('PRP', ['him']), Tree(None, [',']), Tree('IN', ['without']), Tree(Lemma('look.v.01.look'), [Tree('VB', ['looking'])]), Tree('VB', ['at']), Tree('NN', ['anything']), Tree('IN', ['except']), Tree(Lemma('location.n.01.location'), [Tree('NE', [Tree('NNP', ['Drexel', 'Street'])])]), Tree(Lemma('directly.r.01.directly'), [Tree('RB', ['directly'])]), Tree(Lemma('ahead.r.01.in_front'), [Tree('RB', ['in', 'front'])]), Tree('IN', ['of']), Tree('PRP$', ['her']), Tree(None, [',']), Tree('PRP', ['she']), Tree(Lemma('climb.v.01.climb_up'), [Tree('VB', ['climbed', 'up'])]), Tree('IN', ['into']), Tree('NN', ['one']), Tree('IN', ['of']), Tree('DT', ['those']), Tree(Lemma('orange.s.01.orange'), [Tree('JJ', ['orange'])]), Tree(Lemma('streetcar.n.01.streetcar'), [Tree('NN', ['streetcars'])]), Tree(None, [',']), Tree(Lemma('ride_off.v.01.ride_away'), [Tree('VB', ['rode', 'away'])]), Tree('IN', ['in']), Tree('PRP', ['it']), Tree(None, [',']), Tree('CC', ['and']), Tree(Lemma('never.r.01.never'), [Tree('RB', ['never'])]), Tree('come_back.v.00', [Tree('VB', ['came', 'back'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('IN', ['In']), Tree('PRP$', ['his']), Tree('JJ', ['concluding']), Tree('NN', ['paragraph']), Tree('PRP', ['he']), Tree(Lemma('write.v.01.write'), [Tree('VB', ['writes'])]), Tree(None, [':']), Tree(None, ['``']), Tree('DT', ['The']), Tree('JJ', ['devoted']), Tree('NN', ['writer']), Tree('IN', ['of']), Tree('NN', ['humor']), Tree('MD', ['will']), Tree(Lemma('continue.v.01.continue'), [Tree('VB', ['continue'])]), Tree('TO', ['to']), Tree(Lemma('try.v.01.try'), [Tree('VB', ['try'])]), Tree('TO', ['to']), Tree(Lemma('come.v.01.come'), [Tree('VB', ['come'])]), Tree('IN', ['as']), Tree('RB', ['close', 'to']), Tree('NN', ['truth']), Tree('IN', ['as']), Tree('PRP', ['he']), Tree('MD', ['can']), Tree(None, [\"''\"]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('DT', ['The']), Tree('NNP', ['American', 'Registry']), Tree('IN', ['of']), Tree('NNP', ['Pathology']), Tree(Lemma('function.v.01.operate'), [Tree('VB', ['operates'])]), Tree('IN', ['as']), Tree('DT', ['a']), Tree('JJ', ['cooperative']), Tree('NN', ['enterprise']), Tree('IN', ['in']), Tree('JJ', ['medical']), Tree('NN', ['research']), Tree('CC', ['and']), Tree('NN', ['education']), Tree('IN', ['between']), Tree('DT', ['the']), Tree('NN', ['Armed', 'Forces']), Tree('NNP', ['Institute']), Tree('IN', ['of']), Tree('NNP', ['Pathology']), Tree('CC', ['and']), Tree('DT', ['the']), Tree('JJ', ['civilian']), Tree('NN', ['medical', 'profession']), Tree('IN', ['on']), Tree('DT', ['a']), Tree('JJ', ['national']), Tree('CC', ['and']), Tree('JJ', ['international']), Tree('NN', ['basis']), Tree(None, [',']), Tree('IN', ['under']), Tree('JJ', ['such']), Tree('NNS', ['conditions']), Tree('IN', ['as']), Tree('MD', ['may']), Tree('VB', ['be']), Tree(Lemma('agree.v.01.agree'), [Tree('VB', ['agreed'])]), Tree('JJ', ['upon']), Tree('IN', ['between']), Tree('DT', ['the']), Tree('NNP', ['National', 'Research', 'Council']), Tree('CC', ['and']), Tree('DT', ['The']), Tree('NN', ['Surgeons', 'General']), Tree('IN', ['of']), Tree('DT', ['the']), Tree('NNP', ['Army']), Tree(None, [',']), Tree('NNP', ['Navy']), Tree(None, [',']), Tree('CC', ['and']), Tree('NN', ['Air', 'Force']), Tree(None, ['.'])]\n",
      "Sent:  [Tree('DT', ['The']), Tree(Lemma('idea.n.01.idea'), [Tree('NN', ['idea'])]), Tree(Lemma('here.r.02.here'), [Tree('RB', ['here'])]), Tree(Lemma('be.v.02.be'), [Tree('VB', ['is'])]), Tree('JJ', ['one']), Tree('IN', ['of']), Tree(Lemma('discharge.n.02.discharge'), [Tree('NN', ['discharge'])]), Tree('CC', ['but']), Tree('DT', ['this']), Tree('MD', ['must']), Tree(Lemma('stand.v.03.stand'), [Tree('VB', ['stand'])]), Tree('VB', ['in']), Tree(Lemma('opposition.n.02.opposition'), [Tree('NN', ['opposition'])]), Tree('TO', ['to']), Tree('DT', ['a']), Tree(Lemma('second.s.01.second'), [Tree('JJ', ['second'])]), Tree(Lemma('position.n.03.view'), [Tree('NN', ['view'])]), Tree(None, [',']), Tree(Lemma('plato.n.01.Plato'), [Tree('NN', ['Plato'])]), Tree('POS', [\"'s\"]), Tree(Lemma('notion.n.02.notion'), [Tree('NN', ['notion'])]), Tree('IN', ['of']), Tree('DT', ['the']), Tree(Lemma('arousal.n.01.arousal'), [Tree('NN', ['arousal'])]), Tree('IN', ['of']), Tree(Lemma('emotion.n.01.emotion'), [Tree('NN', ['emotion'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('CC', ['And']), Tree('IN', ['with']), Tree('WP', ['what']), Tree(Lemma('resource.n.02.resource'), [Tree('NN', ['resource'])]), Tree('VBD', ['did']), Tree(Lemma('person.n.01.person'), [Tree('NE', [Tree('NNP', ['Prokofieff'])])]), Tree(Lemma('back.v.09.back_up'), [Tree('VB', ['back', 'up'])]), Tree('PRP$', ['his']), Tree(Lemma('creed.n.01.credo'), [Tree('NN', ['Credo'])]), Tree('IN', ['of']), Tree(Lemma('words.n.01.words'), [Tree('NN', ['words'])]), Tree(None, ['-']), Tree('IN', ['with']), Tree(Lemma('downpour.n.01.torrent'), [Tree('NN', ['torrents'])]), Tree('IN', ['of']), Tree(Lemma('powerful.a.01.powerful'), [Tree('JJ', ['powerful'])]), Tree(Lemma('music.n.01.music'), [Tree('NN', ['music'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('EX', ['There']), Tree(Lemma('exist.v.01.be'), [Tree('VB', ['are'])]), Tree(Lemma('besides.r.02.also'), [Tree('RB', ['also'])]), Tree(Lemma('more.r.01.more'), [Tree('RB', ['more'])]), Tree(Lemma('basic.a.01.basic'), [Tree('JJ', ['basic'])]), Tree(Lemma('problem.n.01.problem'), [Tree('NN', ['problems'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('DT', ['The']), Tree('NN', ['industry']), Tree(Lemma('be.v.01.be'), [Tree('VB', ['is'])]), Tree('RB', ['so']), Tree('JJ', ['structured']), Tree('IN', ['that']), Tree('NN', ['price-setting']), Tree('IN', ['by']), Tree('DT', ['a']), Tree('JJ', ['multi-product']), Tree('NN', ['company']), Tree('MD', ['will']), Tree(Lemma('change.v.03.vary'), [Tree('VB', ['vary'])]), Tree('IN', ['with']), Tree('DT', ['the']), Tree('NN', ['way']), Tree('JJ', ['overhead']), Tree('NNS', ['charges']), Tree('VBP', ['are']), Tree(Lemma('allocate.v.01.allocate'), [Tree('VB', ['allocated'])]), Tree(None, ['-']), Tree('IN', ['whether']), Tree('JJ', ['marginal']), Tree('CC', ['or']), Tree('JJ', ['average']), Tree('NN', ['pricing']), Tree('VBZ', ['is']), Tree(Lemma('use.v.01.apply'), [Tree('VB', ['applied'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('WRB', ['Why']), Tree('VBD', ['did']), Tree('PRP', ['they']), Tree(Lemma('prosecute.v.03.engage'), [Tree('VB', ['engage'])]), Tree('VB', ['in']), Tree('DT', ['a']), Tree('NN', ['flood']), Tree('IN', ['of']), Tree('FW', ['mea']), Tree('FW', ['culpas']), Tree(None, [',']), Tree(Lemma('throw.v.01.throw'), [Tree('VB', ['throw'])]), Tree('JJ', ['a', 'few']), Tree('NNS', ['scapegoats']), Tree('TO', ['to']), Tree('DT', ['the']), Tree('NNS', ['dogs']), Tree('CC', ['and']), Tree(Lemma('promise.v.01.promise'), [Tree('VB', ['promise'])]), Tree('TO', ['to']), Tree(Lemma('be.v.01.be'), [Tree('VB', ['be'])]), Tree('JJ', ['good']), Tree('NNS', ['boys']), Tree('RB', ['thereafter']), Tree(None, [',']), Tree(Lemma('express.v.02.express'), [Tree('VB', ['expressing'])]), Tree('PRP$', ['their']), Tree('JJ', ['complete']), Tree('NN', ['confidence']), Tree('IN', ['in']), Tree('DT', ['the']), Tree('NNS', ['laws']), Tree(None, [\"''\"]), Tree(None, ['?'])]\n",
      "Sent:  [Tree('NNP', ['Vernon']), Tree('MD', ['would']), Tree(Lemma('cant.v.01.tilt'), [Tree('VB', ['tilt'])]), Tree('PRP$', ['his']), Tree('NN', ['hat']), Tree('IN', ['over']), Tree('CD', ['one']), Tree('NN', ['ear']), Tree('IN', ['as']), Tree('PRP', ['he']), Tree(Lemma('lounge.v.01.lounge'), [Tree('VB', ['lounged'])]), Tree('IN', ['with']), Tree('PRP$', ['his']), Tree('NNS', ['feet']), Tree('IN', ['on']), Tree('DT', ['the']), Tree('NN', ['dashboard']), Tree(None, [',']), Tree(Lemma('indulge.v.03.indulge'), [Tree('VB', ['indulging'])]), Tree('VB', ['in']), Tree('DT', ['a']), Tree('JJ', ['huge']), Tree('NN', ['cigar']), Tree(None, ['.'])]\n",
      "Sent:  [Tree('JJ', ['Full']), Tree('NN', ['payment']), Tree('IN', ['of']), Tree('NN', ['nursing', 'home']), Tree('NNS', ['bills']), Tree('IN', ['for']), Tree('JJ', ['up', 'to']), Tree('CD', ['180']), Tree('NNS', ['days']), Tree('VBG', ['following']), Tree('NN', ['discharge']), Tree('IN', ['from']), Tree('DT', ['a']), Tree('NN', ['hospital']), Tree(None, ['.'])]\n",
      "Sent:  [Tree(Lemma('long.a.01.long'), [Tree('JJ', ['Long'])]), Tree(Lemma('weekend.n.01.weekend'), [Tree('NN', ['weekends'])]), Tree(Lemma('enable.v.01.enable'), [Tree('VB', ['enable'])]), Tree(Lemma('many.a.01.many'), [Tree('JJ', ['many'])]), Tree('TO', ['to']), Tree(Lemma('escape.v.05.get_away'), [Tree('VB', ['get', 'away'])]), Tree('IN', ['from']), Tree(Lemma('home.r.01.home'), [Tree('RB', ['home'])]), Tree('IN', ['for']), Tree(Lemma('three.s.01.three'), [Tree('JJ', ['three'])]), Tree('CC', ['or']), Tree(Lemma('four.s.01.four'), [Tree('JJ', ['four'])]), Tree(Lemma('day.n.01.day'), [Tree('NN', ['days'])]), Tree('several.s.01', [Tree('JJ', ['several'])]), Tree(Lemma('time.n.01.time'), [Tree('NN', ['times'])]), Tree('DT', ['a']), Tree(Lemma('year.n.01.year'), [Tree('NN', ['year'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree(Lemma('berlin.n.01.Berlin'), [Tree('NN', ['Berlin'])]), Tree('POS', [\"'s\"]), Tree(Lemma('resilience.n.01.resilience'), [Tree('NN', ['resilience'])]), Tree(Lemma('be.v.01.be'), [Tree('VB', ['is'])]), Tree(Lemma('amazing.s.01.amazing'), [Tree('JJ', ['amazing'])]), Tree(None, [',']), Tree('CC', ['but']), Tree('IN', ['if']), Tree('PRP', ['it']), Tree('VB', ['has']), Tree('VB', ['to']), Tree(Lemma('rent.v.04.hire'), [Tree('VB', ['hire'])]), Tree('PRP$', ['its']), Tree(Lemma('labor.n.02.labor'), [Tree('NN', ['labor'])]), Tree('IN', ['in']), Tree('DT', ['the']), Tree(Lemma('west.n.01.West'), [Tree('NN', ['West'])]), Tree('DT', ['the']), Tree(Lemma('struggle.n.01.struggle'), [Tree('NN', ['struggle'])]), Tree('MD', ['will']), Tree(Lemma('be.v.01.be'), [Tree('VB', ['be'])]), Tree(Lemma('difficult.a.01.hard'), [Tree('JJ', ['hard'])]), Tree(Lemma('indeed.r.01.indeed'), [Tree('RB', ['indeed'])]), Tree(None, [\"''\"]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('IN', ['In']), Tree('DT', ['the']), Tree('JJ', ['brief']), Tree('NN', ['moment']), Tree('PRP', ['I']), Tree('have.v.00', [Tree('VB', ['had'])]), Tree('VB', ['to']), Tree(Lemma('talk.v.01.talk'), [Tree('VB', ['talk'])]), Tree('TO', ['to']), Tree('PRP', ['them']), Tree('IN', ['before']), Tree('PRP', ['I']), Tree(Lemma('fill.v.04.take'), [Tree('VB', ['took'])]), Tree('PRP$', ['my']), Tree('NN', ['post']), Tree('IN', ['on']), Tree('DT', ['the']), Tree('NN', ['ring']), Tree('IN', ['of']), Tree('NNS', ['defenses']), Tree(None, [',']), Tree('PRP', ['I']), Tree(Lemma('indicate.v.02.indicate'), [Tree('VB', ['indicated'])]), Tree('PRP', ['I']), Tree('VBD', ['was']), Tree(Lemma('disgust.v.02.sicken'), [Tree('VB', ['sickened'])]), Tree('IN', ['by']), Tree('DT', ['the']), Tree('NNS', ['methods']), Tree('NNS', ['men']), Tree(Lemma('use.v.01.employ'), [Tree('VB', ['employed'])]), Tree('TO', ['to']), Tree(Lemma('survive.v.01.live'), [Tree('VB', ['live'])]), Tree('CC', ['and']), Tree(Lemma('trade.v.01.trade'), [Tree('VB', ['trade'])]), Tree('IN', ['on']), Tree('DT', ['the']), Tree('NN', ['river']), Tree(None, ['.'])]\n",
      "Sent:  [Tree('DT', ['The']), Tree('NN', ['forest']), Tree(Lemma('assume.v.03.take_on'), [Tree('VB', ['took', 'on'])]), Tree('DT', ['an']), Tree('JJ', ['impersonal']), Tree('NN', ['aspect']), Tree(None, ['.'])]\n",
      "Sent:  [Tree('DT', ['This']), Tree(Lemma('prove.v.02.prove'), [Tree('VB', ['proved'])]), Tree('RB', ['conclusively']), Tree('IN', ['that']), Tree('DT', ['The']), Tree('NNP', ['Wrangler']), Tree(Lemma('be.v.01.be'), [Tree('VB', ['was'])]), Tree('DT', ['a']), Tree('NN', ['jinx']), Tree(None, [',']), Tree('RB', ['so']), Tree('PRP', ['he']), Tree(Lemma('walk.v.01.walk'), [Tree('VB', ['walked'])]), Tree('IN', ['on']), Tree('RB', ['down']), Tree('TO', ['to']), Tree('NNP', ['Hurrays']), Tree(None, [',']), Tree('DT', ['an']), Tree('RB', ['even']), Tree('RBR', ['more']), Tree('JJ', ['glorified']), Tree('NN', ['gambling', 'den']), Tree('IN', ['than']), Tree('DT', ['the']), Tree('NN', ['Golden', 'Calf']), Tree(None, ['.'])]\n",
      "Sent:  [Tree('DT', ['This']), Tree('VBZ', ['is']), Tree(Lemma('not.r.01.not'), [Tree('RB', ['not'])]), Tree(Lemma('extend.v.04.extend'), [Tree('VB', ['extended'])]), Tree('VB', ['to']), Tree(Lemma('anticipated.s.01.anticipated'), [Tree('JJ', ['anticipated'])]), Tree(Lemma('degree.n.01.level'), [Tree('NN', ['levels'])]), Tree('IN', ['of']), Tree(Lemma('gross_national_product.n.01.GNP'), [Tree('NN', ['GNP'])]), Tree(None, [',']), Tree(Lemma('however.r.01.however'), [Tree('RB', ['however'])]), Tree(None, ['-']), Tree('RB', ['only']), Tree('DT', ['the']), Tree(Lemma('current.a.01.current'), [Tree('JJ', ['current'])]), Tree(Lemma('degree.n.01.level'), [Tree('NN', ['level'])]), Tree('IN', ['of']), Tree(Lemma('gross_national_product.n.01.GNP'), [Tree('NN', ['GNP'])]), Tree(Lemma('affect.v.01.affect'), [Tree('VB', ['affects'])]), Tree('DT', ['the']), Tree(Lemma('populace.n.01.public'), [Tree('NN', ['public'])]), Tree(Lemma('pressure.n.02.pressure'), [Tree('NN', ['pressure'])]), Tree('IN', ['against']), Tree(Lemma('wage.n.01.wage'), [Tree('NN', ['wage'])]), Tree(Lemma('monetary_value.n.01.price'), [Tree('NN', ['price'])]), Tree(Lemma('addition.n.03.increase'), [Tree('NN', ['increases'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('DT', ['Some']), Tree('JJ', ['interfaith']), Tree('NNS', ['tensions']), Tree('VBP', ['are']), Tree('RB', ['not']), Tree(Lemma('occasion.v.01.occasion'), [Tree('VB', ['occasioned'])]), Tree('IN', ['by']), Tree('JJ', ['theological']), Tree('NNS', ['differences']), Tree('RB', ['at', 'all']), Tree(None, [',']), Tree('CC', ['but']), Tree('IN', ['by']), Tree('DT', ['the']), Tree('NN', ['need']), Tree('IN', ['of']), Tree('NNS', ['men']), Tree('TO', ['to']), Tree(Lemma('have.v.01.have'), [Tree('VB', ['have'])]), Tree('NNS', ['persons']), Tree('PRP', ['they']), Tree('MD', ['can']), Tree(Lemma('blame.v.02.blame'), [Tree('VB', ['blame'])]), Tree(None, [',']), Tree(Lemma('distrust.v.01.distrust'), [Tree('VB', ['distrust'])]), Tree(None, [',']), Tree(Lemma('denounce.v.01.denounce'), [Tree('VB', ['denounce'])]), Tree(None, [',']), Tree('CC', ['and']), Tree('RB', ['even']), Tree(Lemma('hate.v.01.hate'), [Tree('VB', ['hate'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('PRP$', ['Their']), Tree('NN', ['mother']), Tree(Lemma('be.v.02.be'), [Tree('VB', ['is'])]), Tree('NNP', ['Mrs.', 'Camilla', 'Alsop', 'Wendell']), Tree(None, ['.'])]\n",
      "Sent:  [Tree('PRP', ['We']), Tree('MD', ['could']), Tree(\"n't.r.00\", [Tree('RB', [\"n't\"])]), Tree('VB', ['help']), Tree(Lemma('laugh.v.01.laugh'), [Tree('VB', ['laughing'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('NNS', ['Realtors']), Tree(None, [',']), Tree('DT', ['both']), Tree('RB', ['generally']), Tree('CC', ['and']), Tree('RB', ['in', 'this']), Tree('NN', ['group']), Tree(None, [',']), Tree('VBP', ['have']), Tree('RB', ['invariably']), Tree(Lemma('compare.v.03.equate'), [Tree('VB', ['equated'])]), Tree('JJ', ['residential']), Tree('NN', ['integration']), Tree('IN', ['with']), Tree('DT', ['a']), Tree('NN', ['decline']), Tree('IN', ['in']), Tree('NN', ['property']), Tree('NNS', ['values']), Tree(None, [',']), Tree('DT', ['a']), Tree('NN', ['circumstance']), Tree(Lemma('see.v.05.view'), [Tree('VB', ['viewed'])]), Tree('IN', ['with']), Tree('JJ', ['considerable']), Tree('NN', ['apprehension']), Tree(None, ['.'])]\n",
      "Sent:  [Tree('CD', ['Two']), Tree('NNS', ['counts']), Tree('IN', ['of']), Tree('NN', ['assault']), Tree('IN', ['on']), Tree('DT', ['an']), Tree('NN', ['officer']), Tree(None, [',']), Tree('NN', ['resisting', 'arrest']), Tree(None, [',']), Tree('NN', ['disturbance']), Tree('CC', ['and']), Tree(Lemma('curse.v.01.curse'), [Tree('VB', ['cursing'])]), Tree(None, [',']), Tree('NN', ['police']), Tree(Lemma('state.v.01.say'), [Tree('VB', ['said'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('NNP', ['Parker']), Tree('VB', ['meant', 'business']), Tree(None, ['.'])]\n",
      "Sent:  [Tree(None, ['``']), Tree('UH', ['Well']), Tree(None, [',']), Tree('IN', ['that']), Tree('VBZ', [\"'s\"]), Tree(Lemma('complete.s.05.over'), [Tree('JJ', ['over'])]), Tree(Lemma('nowadays.r.01.now'), [Tree('RB', ['now'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('NNP', ['Jouvet']), Tree(Lemma('act.v.03.play'), [Tree('VB', ['played'])]), Tree('PRP', ['him']), Tree('IN', ['as']), Tree('DT', ['a']), Tree('JJ', ['sincere']), Tree('NN', ['zealot']), Tree(None, [',']), Tree('CC', ['and']), Tree('NNP', ['Ledoux']), Tree(None, [',']), Tree('IN', ['at']), Tree('DT', ['the']), Tree('NNP', ['Comedie']), Tree(None, [',']), Tree(Lemma('make.v.02.make'), [Tree('VB', ['made'])]), Tree('PRP', ['him']), Tree('DT', ['a']), Tree('JJ', ['gross']), Tree('NN', ['buffoon']), Tree(None, [',']), Tree('RB', ['or', 'so']), Tree('DT', ['the']), Tree('NNS', ['historians']), Tree(Lemma('tell.v.02.tell'), [Tree('VB', ['tell'])]), Tree('PRP', ['us']), Tree(None, ['.'])]\n",
      "Sent:  [Tree('DT', ['The']), Tree('NN', ['lawyer']), Tree('IN', ['with']), Tree('WP', ['whom']), Tree('PRP', ['I']), Tree(Lemma('study.v.02.study'), [Tree('VB', ['studied'])]), Tree('NN', ['law']), Tree(Lemma('steer.v.01.steer'), [Tree('VB', ['steered'])]), Tree('PRP', ['me']), Tree('IN', ['off']), Tree('DT', ['the']), Tree('NNP', ['Socialist']), Tree('NN', ['track']), Tree(None, ['.'])]\n",
      "Sent:  [Tree('NNP', ['Sponsor']), Tree(Lemma('quote.v.01.quote'), [Tree('VB', ['quotes'])]), Tree('NNP', ['John', 'McLendon']), Tree('IN', ['of']), Tree('DT', ['the']), Tree('NNP', ['McLendon-Ebony']), Tree('NN', ['station']), Tree('NN', ['group']), Tree('IN', ['as']), Tree(Lemma('allege.v.01.say'), [Tree('VB', ['saying'])]), Tree('IN', ['that']), Tree('DT', ['the']), Tree('NNP', ['Southern', 'Negro']), Tree('VBZ', ['is']), Tree(Lemma('become.v.01.become'), [Tree('VB', ['becoming'])]), Tree('JJ', ['conscious', 'of']), Tree('NN', ['quality']), Tree('CC', ['and']), Tree('CC', ['and']), Tree(None, ['``']), Tree('VBZ', ['does']), Tree('RB', ['not']), Tree(Lemma('wish.v.02.wish'), [Tree('VB', ['wish'])]), Tree('VB', ['to']), Tree('VB', ['be']), Tree('JJ', ['associated']), Tree('VB', ['with']), Tree('NN', ['radio']), Tree('WDT', ['which']), Tree(Lemma('be.v.01.be'), [Tree('VB', ['is'])]), Tree('DT', ['any']), Tree('NN', ['way']), Tree('JJ', ['degrading']), Tree('TO', ['to']), Tree('PRP$', ['his']), Tree('NN', ['race']), Tree(None, [';']), Tree('PRP', ['he']), Tree(Lemma('tend.v.01.tend'), [Tree('VB', ['tends'])]), Tree('VB', ['to']), Tree(Lemma('shy_away_from.v.01.shy_away_from'), [Tree('VB', ['shy', 'away', 'from'])]), Tree('DT', ['the']), Tree('JJ', ['hooting']), Tree('CC', ['and']), Tree('NN', ['hollering']), Tree('NNS', ['personalities']), Tree('IN', ['that']), Tree('RB', ['originally']), Tree(Lemma('make.v.02.make'), [Tree('VB', ['made'])]), Tree('NNP', ['Negro']), Tree('NN', ['radio']), Tree('NNS', ['programs']), Tree('JJ', ['famous']), Tree(None, [\"''\"]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('IN', ['In']), Tree(Lemma('affirm.v.02.affirm'), [Tree('VB', ['affirming'])]), Tree('DT', ['this']), Tree('PRP', ['we']), Tree('VBP', ['have']), Tree(Lemma('already.r.01.already'), [Tree('RB', ['already'])]), Tree(Lemma('take.v.01.take'), [Tree('VB', ['taken'])]), Tree('DT', ['the']), Tree(Lemma('decisive.a.01.decisive'), [Tree('JJ', ['decisive'])]), Tree(Lemma('measure.n.01.step'), [Tree('NN', ['step'])]), Tree('VB', ['in']), Tree(Lemma('interrupt.v.04.break'), [Tree('VB', ['breaking'])]), Tree('DT', ['the']), Tree(Lemma('deadlock.n.01.deadlock'), [Tree('NN', ['deadlock'])]), Tree('IN', ['into']), Tree('WDT', ['which']), Tree(Lemma('person.n.01.person'), [Tree('NE', [Tree('NNP', ['Bultmann'])])]), Tree('POS', [\"'s\"]), Tree(Lemma('attempt.n.01.attempt'), [Tree('NN', ['attempt'])]), Tree('TO', ['to']), Tree(Lemma('explicate.v.02.formulate'), [Tree('VB', ['formulate'])]), Tree('such.s.00', [Tree('JJ', ['such'])]), Tree('DT', ['a']), Tree(Lemma('theology.n.01.theology'), [Tree('NN', ['theology'])]), Tree('VBZ', ['has']), Tree(Lemma('leave.v.07.lead'), [Tree('VB', ['led'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('DT', ['The']), Tree(Lemma('inhabitant.n.01.dweller'), [Tree('NN', ['dweller'])]), Tree('IN', ['at']), Tree('NN', ['p']), Tree(Lemma('be.v.01.be'), [Tree('VB', ['is'])]), Tree(Lemma('last.a.02.last'), [Tree('JJ', ['last'])]), Tree('TO', ['to']), Tree(Lemma('learn.v.02.hear'), [Tree('VB', ['hear'])]), Tree('VB', ['about']), Tree('DT', ['a']), Tree(Lemma('new.a.01.new'), [Tree('JJ', ['new'])]), Tree(Lemma('remedy.n.02.cure'), [Tree('NN', ['cure'])]), Tree(None, [',']), Tree('DT', ['the']), Tree(Lemma('slow.a.01.slow'), [Tree('JJ', ['slowest'])]), Tree('TO', ['to']), Tree(Lemma('announce.v.01.announce'), [Tree('VB', ['announce'])]), Tree('TO', ['to']), Tree('PRP$', ['his']), Tree(Lemma('neighbor.n.01.neighbor'), [Tree('NN', ['neighbors'])]), Tree('PRP$', ['his']), Tree(Lemma('pressing.s.01.urgent'), [Tree('JJ', ['urgent'])]), Tree(Lemma('distress.n.02.distress'), [Tree('NN', ['distresses'])]), Tree(None, [',']), Tree('DT', ['the']), Tree('NN', ['one']), Tree('WP', ['who']), Tree(Lemma('travel.v.01.go'), [Tree('VB', ['goes'])]), Tree('DT', ['the']), Tree(Lemma('farthest.r.01.farthest'), [Tree('RB', ['farthest'])]), Tree('TO', ['to']), Tree(Lemma('trade.v.01.trade'), [Tree('VB', ['trade'])]), Tree(None, [',']), Tree('CC', ['and']), Tree('DT', ['the']), Tree('NN', ['one']), Tree('IN', ['with']), Tree('DT', ['the']), Tree('great.s.00', [Tree('JJ', ['greatest'])]), Tree(Lemma('trouble.n.04.difficulty'), [Tree('NN', ['difficulty'])]), Tree('IN', ['of']), Tree('JJ', ['all']), Tree('JJ', ['in']), Tree(Lemma('get_across.v.01.put_over'), [Tree('VB', ['putting', 'over'])]), Tree('DT', ['an']), Tree(Lemma('mind.n.06.idea'), [Tree('NN', ['idea'])]), Tree('CC', ['or']), Tree(Lemma('get.v.03.get'), [Tree('VB', ['getting'])]), Tree(Lemma('people.n.01.people'), [Tree('NN', ['people'])]), Tree('TO', ['to']), Tree(Lemma('join.v.01.join'), [Tree('VB', ['join'])]), Tree('PRP', ['him']), Tree('IN', ['in']), Tree('DT', ['a']), Tree(Lemma('concerted.s.01.cooperative'), [Tree('JJ', ['cooperative'])]), Tree(Lemma('attempt.n.01.effort'), [Tree('NN', ['effort'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('IN', ['As']), Tree('DT', ['a']), Tree(Lemma('composer.n.01.composer'), [Tree('NN', ['composer'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree(Lemma('lincoln.n.01.Abraham_Lincoln'), [Tree('NN', ['Abraham', 'Lincoln'])]), Tree(Lemma('emerge.v.03.emerge'), [Tree('VB', ['emerged'])]), Tree('RB', ['as']), Tree('DT', ['an']), Tree(Lemma('embodiment.n.01.incarnation'), [Tree('NN', ['incarnation'])]), Tree('IN', ['of']), Tree('DT', ['the']), Tree(Lemma('national.a.01.national'), [Tree('JJ', ['national'])]), Tree(Lemma('fundamental_law.n.01.constitution'), [Tree('NN', ['Constitution'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('PRP', ['I']), Tree(Lemma('besides.r.02.also'), [Tree('RB', ['also'])]), Tree(Lemma('hope.v.02.hope'), [Tree('VB', ['hope'])]), Tree('IN', ['that']), Tree('PRP', ['we']), Tree('MD', ['can']), Tree(Lemma('make.v.01.do'), [Tree('VB', ['do'])]), Tree('VB', ['something']), Tree('IN', ['about']), Tree(Lemma('reduce.v.01.reduce'), [Tree('VB', ['reducing'])]), Tree('DT', ['the']), Tree('NN', ['infant', 'mortality', 'rate']), Tree('IN', ['of']), Tree(Lemma('idea.n.01.idea'), [Tree('NN', ['ideas'])]), Tree(None, ['-']), Tree('DT', ['an']), Tree('NN', ['affliction']), Tree('IN', ['of']), Tree('DT', ['all']), Tree(Lemma('bureaucracy.n.01.bureaucracy'), [Tree('NN', ['bureaucracies'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('RB', ['Hence']), Tree('PRP', ['he']), Tree(Lemma('be.v.01.be'), [Tree('VB', ['was'])]), Tree('IN', ['in']), Tree('PRP$', ['his']), Tree('NN', ['lifetime']), Tree(None, [',']), Tree('IN', ['as']), Tree(Lemma('be.v.01.be'), [Tree('VB', ['is'])]), Tree('DT', ['the']), Tree('NN', ['memory']), Tree('IN', ['of']), Tree('PRP', ['him']), Tree('RB', ['afterwards']), Tree(None, [',']), Tree('DT', ['a']), Tree('NN', ['canker']), Tree('IN', ['within']), Tree('DT', ['the']), Tree('JJ', ['liberal']), Tree('NN', ['sensitivity']), Tree(None, ['.'])]\n",
      "Sent:  [Tree(None, ['``']), Tree('UH', ['Oh']), Tree(None, [',']), Tree('VBP', ['do']), Tree(Lemma('forgive.v.01.forgive'), [Tree('VB', ['forgive'])]), Tree('PRP', ['me']), Tree(None, ['.'])]\n",
      "Sent:  [Tree(None, ['``']), Tree('NN', ['Wagon', 'Train']), Tree(None, [\"''\"]), Tree('VBZ', ['is']), Tree(Lemma('report.v.02.report'), [Tree('VB', ['reported'])]), Tree('DT', ['the']), Tree('NN', ['No.']), Tree('CD', ['1']), Tree('NN', ['TV', 'show']), Tree(None, ['.'])]\n",
      "Sent:  [Tree('PRP$', ['His']), Tree(Lemma('bel_canto.n.01.bel_canto'), [Tree('NN', ['bel', 'canto'])]), Tree(Lemma('expressive_style.n.01.style'), [Tree('NN', ['style'])]), Tree(Lemma('establish.v.05.give'), [Tree('VB', ['gave'])]), Tree('DT', ['the']), Tree(Lemma('performance.n.01.performance'), [Tree('NN', ['performance'])]), Tree('DT', ['a']), Tree(Lemma('particular.s.01.special'), [Tree('JJ', ['special'])]), Tree(Lemma('eminence.n.01.distinction'), [Tree('NN', ['distinction'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('PRP', ['He']), Tree('hold.v.1;2', [Tree('VB', ['held'])]), Tree('DT', ['the']), Tree(Lemma('control.n.09.control'), [Tree('NN', ['controls'])]), Tree('WRB', ['where']), Tree('PRP', ['they']), Tree('VBD', ['had']), Tree(Lemma('be.v.03.be'), [Tree('VB', ['been'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('NNP', ['George', 'E.', 'Sweazey']), Tree(Lemma('write.v.02.write'), [Tree('VB', ['writes'])]), Tree(None, [':']), Tree(None, ['``']), Tree('EX', ['There']), Tree(Lemma('be.v.01.be'), [Tree('VB', ['is'])]), Tree('NN', ['danger']), Tree('IN', ['in']), Tree(Lemma('try.v.01.try'), [Tree('VB', ['trying'])]), Tree('TO', ['to']), Tree(Lemma('make.v.02.make'), [Tree('VB', ['make'])]), Tree('NN', ['admission']), Tree('TO', ['to']), Tree('DT', ['the']), Tree('NNP', ['Church']), Tree('RB', ['so']), Tree('JJ', ['easy']), Tree('CC', ['and']), Tree('JJ', ['painless']), Tree('IN', ['that']), Tree('NNS', ['people']), Tree('MD', ['will']), Tree('RB', ['scarcely']), Tree(Lemma('know.v.01.know'), [Tree('VB', ['know'])]), Tree('IN', ['that']), Tree('NN', ['anything']), Tree('VBZ', ['has']), Tree(Lemma('happen.v.01.happen'), [Tree('VB', ['happened'])]), Tree(None, [\"''\"]), Tree(None, ['.'])]\n",
      "Sent:  [Tree(Lemma('possibly.r.01.perhaps'), [Tree('RB', ['Perhaps'])]), Tree('DT', ['the']), Tree(Lemma('group.n.01.group'), [Tree('NE', [Tree('NNP', ['Pirate'])])]), Tree('WP', ['who']), Tree('MD', ['will']), Tree(Lemma('be.v.01.be'), [Tree('VB', ['be'])]), Tree('DT', ['the']), Tree(Lemma('unhappy.a.01.unhappy'), [Tree('JJ', ['unhappiest'])]), Tree('IN', ['over']), Tree('DT', ['the']), Tree(Lemma('news.n.02.news'), [Tree('NN', ['news'])]), Tree('IN', ['that']), Tree(Lemma('person.n.01.person'), [Tree('NE', [Tree('NNP', ['Musial'])])]), Tree(Lemma('probably.r.01.probably'), [Tree('RB', ['probably'])]), Tree('MD', ['will']), Tree(Lemma('sit_out.v.01.sit_out'), [Tree('VB', ['sit', 'out'])]), Tree(Lemma('most.a.02.most'), [Tree('JJ', ['most'])]), Tree('JJ', ['of']), Tree('DT', ['the']), Tree(Lemma('series.n.01.series'), [Tree('NN', ['series'])]), Tree(Lemma('be.v.02.be'), [Tree('VB', ['is'])]), Tree(Lemma('person.n.01.person'), [Tree('NE', [Tree('NNP', ['Bob', 'Friend'])])]), Tree(None, [',']), Tree('WP', ['who']), Tree('VBD', ['was']), Tree(Lemma('beat.v.01.beat'), [Tree('VB', ['beaten'])]), Tree('IN', ['by']), Tree(Lemma('person.n.01.person'), [Tree('NE', [Tree('NNP', ['The', 'Man'])])]), Tree(Lemma('twice.r.01.twice'), [Tree('RB', ['twice'])]), Tree(Lemma('last.s.01.last'), [Tree('JJ', ['last'])]), Tree(Lemma('season.n.01.season'), [Tree('NN', ['season'])]), Tree('IN', ['on']), Tree(Lemma('dramatic.a.01.dramatic'), [Tree('JJ', ['dramatic'])]), Tree(Lemma('homer.n.01.home_run'), [Tree('NN', ['home', 'runs'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('IN', ['If']), Tree('PRP', ['they']), Tree('VB', ['have']), Tree('VB', ['to']), Tree(Lemma('take.v.09.take'), [Tree('VB', ['take'])]), Tree('DT', ['any']), Tree('NN', ['car']), Tree(None, [',']), Tree('PRP', ['they']), Tree('MD', [\"'d\"]), Tree('RB', ['rather']), Tree(Lemma('take.v.09.take'), [Tree('VB', ['take'])]), Tree('DT', ['the']), Tree('JJ', ['big']), Tree('CD', ['one']), Tree(None, ['.'])]\n",
      "Sent:  [Tree('DT', ['The']), Tree(Lemma('pale.s.04.pale'), [Tree('JJ', ['pale'])]), Tree(Lemma('blob.n.01.blob'), [Tree('NN', ['blob'])]), Tree('IN', ['of']), Tree('DT', ['the']), Tree(Lemma('woman.n.01.woman'), [Tree('NN', ['woman'])]), Tree(Lemma('disappear.v.01.disappear'), [Tree('VB', ['disappeared'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree(None, ['``']), Tree('WP', ['What']), Tree('RB', ['else']), Tree(None, [\"''\"]), Tree(None, ['?'])]\n",
      "Sent:  [Tree(None, ['``']), Tree('DT', ['The']), Tree('JJ', ['first']), Tree('CD', ['two']), Tree('NNS', ['pilots']), Tree('VBD', ['had']), Tree(Lemma('crash.v.01.crash'), [Tree('VB', ['crashed'])]), Tree(None, [\"''\"]), Tree(None, [',']), Tree('PRP', ['he']), Tree(Lemma('state.v.01.say'), [Tree('VB', ['said'])]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('DT', ['A']), Tree('JJ', ['final']), Tree('NN', ['factor']), Tree('WDT', ['which']), Tree(Lemma('lend.v.01.contribute'), [Tree('VB', ['contributed'])]), Tree('RB', ['greatly']), Tree('TO', ['to']), Tree('DT', ['the']), Tree('NN', ['fragmentation']), Tree('IN', ['of']), Tree('DT', ['the']), Tree('NNP', ['Congo']), Tree(None, [',']), Tree('RB', ['immediately']), Tree('IN', ['after']), Tree('NN', ['independence']), Tree(None, [',']), Tree(Lemma('be.v.02.be'), [Tree('VB', ['was'])]), Tree('DT', ['the']), Tree('JJ', ['provincial']), Tree('NN', ['structure']), Tree('WDT', ['that']), Tree('VBD', ['had']), Tree('VBN', ['been']), Tree(Lemma('lay_down.v.01.establish'), [Tree('VB', ['established'])]), Tree('IN', ['by']), Tree('DT', ['the']), Tree('NNPS', ['Belgians']), Tree('IN', ['for']), Tree('NN', ['convenience']), Tree('IN', ['in']), Tree('NN', ['administration']), Tree(None, ['.'])]\n",
      "Sent:  [Tree('DT', ['The']), Tree(None, ['``']), Tree('NNP', ['Essex', 'Journal']), Tree(None, [\"''\"]), Tree(Lemma('read.v.02.say'), [Tree('VB', ['says'])]), Tree('IN', ['that']), Tree('PRP', ['he']), Tree(None, ['``']), Tree(Lemma('deliver.v.01.deliver'), [Tree('VB', ['delivered'])]), Tree('DT', ['an']), Tree('NN', ['oration']), Tree('IN', ['on']), Tree('DT', ['the']), Tree('NN', ['bridge']), Tree(None, [',']), Tree('WDT', ['which']), Tree('IN', ['for']), Tree('NN', ['elegance']), Tree('IN', ['of']), Tree('NN', ['style']), Tree(None, [',']), Tree('NN', ['propriety']), Tree('IN', ['of']), Tree('NN', ['speech']), Tree('CC', ['or']), Tree('NN', ['force']), Tree('IN', ['of']), Tree('NN', ['argument']), Tree(None, [',']), Tree(Lemma('be.v.01.be'), [Tree('VB', ['was'])]), Tree('RB', ['truly']), Tree('JJ', ['Ciceronian']), Tree(None, [\"''\"]), Tree(None, ['.'])]\n",
      "Sent:  [Tree('CC', ['And']), Tree('NNP', ['Marie', 'Antoinette']), Tree(None, ['-']), Tree('NNP', ['Jacqueline', 'Bouvier']), Tree(None, ['.'])]\n"
     ]
    }
   ],
   "source": [
    "for sent in sent_list:\n",
    "    print(\"Sent: \", sent)\n",
    "\n",
    "    for word in sent:\n",
    "        pass\n",
    "        # print(\"Pos Tag:\", word, \" - - - \", word.pos()[0][0])\n",
    "        # print(\"Word: \", word, \"PoS: \", get_postag(word), \"Value: \", get_walue(word))\n",
    "        # word, \"| Label:\", word.label(), \"| Leaves:\", word.leaves()[0], \"| PoS Tag:\", word.pos()\n",
    "        # print(\" --> \", get_walue(word))\n",
    "        # if(get_postag(word) == \"NN\"):\n",
    "        #     print(\"Nome --> \", get_walue(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selezione delle frasi casuali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andiamo ad estrarre le frasi, a ripulirle e ad estrarre una parola casuale.\n",
    "\n",
    "Insieme al sostantivo vogliamo anche estrarre il PoS tga associato, per controllare\n",
    "appunto che sia un sostantivo e il sysnet associato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_sents(sents, num):\n",
    "    rand_sents = []\n",
    "    rand_num = []\n",
    "    n = random.randint(0, len(sents))\n",
    "    \n",
    "    for i in range(num):\n",
    "        while(n in rand_num):\n",
    "            n = random.randint(0, len(sents))\n",
    "        rand_num.append(n)\n",
    "        rand_sents.append(sents[n])\n",
    "    \n",
    "    return rand_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_list = pick_sents(sents, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrarre il sostantivo e il synset corretto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estraiamo le frasi i formato *sent*, che Ã¨ caraterizzato da una struttura ad albero e contiene\n",
    "i PoS tag e i sysnet, se ci sono, di 50 frasi estratte casualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_list = pick_sents(semcor.tagged_sents(tag='both'), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree('DT', ['The']),\n",
       " Tree(Lemma('group.n.01.group'), [Tree('NE', [Tree('NNP', ['Fulton', 'County', 'Grand', 'Jury'])])]),\n",
       " Tree(Lemma('state.v.01.say'), [Tree('VB', ['said'])]),\n",
       " Tree(Lemma('friday.n.01.Friday'), [Tree('NN', ['Friday'])]),\n",
       " Tree('DT', ['an']),\n",
       " Tree(Lemma('probe.n.01.investigation'), [Tree('NN', ['investigation'])]),\n",
       " Tree('IN', ['of']),\n",
       " Tree(Lemma('atlanta.n.01.Atlanta'), [Tree('NN', ['Atlanta'])]),\n",
       " Tree('POS', [\"'s\"]),\n",
       " Tree(Lemma('late.s.03.recent'), [Tree('JJ', ['recent'])]),\n",
       " Tree(Lemma('primary.n.01.primary_election'), [Tree('NN', ['primary', 'election'])]),\n",
       " Tree(Lemma('produce.v.04.produce'), [Tree('VB', ['produced'])]),\n",
       " Tree(None, ['``']),\n",
       " Tree('DT', ['no']),\n",
       " Tree(Lemma('evidence.n.01.evidence'), [Tree('NN', ['evidence'])]),\n",
       " Tree(None, [\"''\"]),\n",
       " Tree('IN', ['that']),\n",
       " Tree('DT', ['any']),\n",
       " Tree(Lemma('abnormality.n.04.irregularity'), [Tree('NN', ['irregularities'])]),\n",
       " Tree(Lemma('happen.v.01.take_place'), [Tree('VB', ['took', 'place'])]),\n",
       " Tree(None, ['.'])]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semcor.tagged_sents(tag='both')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree('DT', ['The']),\n",
       " Tree(Lemma('game.n.01.game'), [Tree('NN', ['game'])]),\n",
       " Tree('VBD', ['was']),\n",
       " Tree(Lemma('resume.v.01.resume'), [Tree('VB', ['resumed'])]),\n",
       " Tree(None, ['.'])]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_list[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estraggo un sostantivo per ogni frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: IN\n",
      "Label: appeal_to.v.00\n",
      "Label: DT\n",
      "Label: NNP\n",
      "Label: CC\n",
      "Label: TO\n",
      "Label: NNP\n",
      "Label: None\n",
      "Label: PRP\n",
      "Label: JJ\n",
      "Label: appeal_to.v.00\n",
      "Label: DT\n",
      "Label: NNP\n",
      "Label: IN\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: CC\n",
      "Label: VBD\n",
      "Label: Lemma('refuse.v.02.reject')\n",
      "Label: None\n",
      "Label: None\n",
      "Label: IN\n",
      "Label: PRP\n",
      "Label: Lemma('look.v.01.look')\n",
      "Label: with_nostalgia.r.00\n",
      "Label: TO\n",
      "Label: DT\n",
      "Label: Lemma('society.n.01.society')\n",
      "Label: WDT\n",
      "Label: VBD\n",
      "Label: VBN\n",
      "Label: Lemma('wipe_out.v.03.sweep_away')\n",
      "Label: None\n",
      "Label: PRP\n",
      "Label: Lemma('be.v.01.be')\n",
      "Label: Lemma('probably.r.01.probably')\n",
      "Label: Lemma('no.r.01.no_more')\n",
      "Label: RB\n",
      "Label: Lemma('half.s.02.half')\n",
      "Label: Lemma('conscious.a.02.conscious')\n",
      "Label: IN\n",
      "Label: PRP\n",
      "Label: NNS\n",
      "Label: WDT\n",
      "Label: VBD\n",
      "Label: Lemma('never.r.01.never')\n",
      "Label: Lemma('exist.v.01.exist')\n",
      "Label: None\n",
      "Label: IN\n",
      "Label: RB\n",
      "Label: None\n",
      "Label: Lemma('visit.v.01.visit')\n",
      "Label: NN\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: PRP$\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: RB\n",
      "Label: None\n",
      "Label: IN\n",
      "Label: PRP\n",
      "Label: Lemma('be.v.02.be')\n",
      "Label: DT\n",
      "Label: RB\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: EX\n",
      "Label: Lemma('be.v.01.be')\n",
      "Label: JJ\n",
      "Label: NNS\n",
      "Label: WDT\n",
      "Label: Lemma('be.v.01.be')\n",
      "Label: JJ\n",
      "Label: CC\n",
      "Label: JJ\n",
      "Label: IN\n",
      "Label: Lemma('address.v.01.address')\n",
      "Label: PRP$\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: Lemma('person.n.01.person')\n",
      "Label: POS\n",
      "Label: Lemma('twelve.n.01.dozen')\n",
      "Label: VBD\n",
      "Label: Lemma('honestly.r.01.honestly')\n",
      "Label: Lemma('earn.v.02.earn')\n",
      "Label: None\n",
      "Label: IN\n",
      "Label: Lemma('look.v.01.look')\n",
      "Label: VB\n",
      "Label: PRP\n",
      "Label: None\n",
      "Label: IN\n",
      "Label: Lemma('look.v.01.look')\n",
      "Label: VB\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: Lemma('location.n.01.location')\n",
      "Label: Lemma('directly.r.01.directly')\n",
      "Label: Lemma('ahead.r.01.in_front')\n",
      "Label: IN\n",
      "Label: PRP$\n",
      "Label: None\n",
      "Label: PRP\n",
      "Label: Lemma('climb.v.01.climb_up')\n",
      "Label: IN\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: Lemma('orange.s.01.orange')\n",
      "Label: Lemma('streetcar.n.01.streetcar')\n",
      "Label: None\n",
      "Label: Lemma('ride_off.v.01.ride_away')\n",
      "Label: IN\n",
      "Label: PRP\n",
      "Label: None\n",
      "Label: CC\n",
      "Label: Lemma('never.r.01.never')\n",
      "Label: come_back.v.00\n",
      "Label: None\n",
      "Label: IN\n",
      "Label: PRP$\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: PRP\n",
      "Label: Lemma('write.v.01.write')\n",
      "Label: None\n",
      "Label: None\n",
      "Label: DT\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: NN\n",
      "Label: MD\n",
      "Label: Lemma('continue.v.01.continue')\n",
      "Label: TO\n",
      "Label: Lemma('try.v.01.try')\n",
      "Label: TO\n",
      "Label: Lemma('come.v.01.come')\n",
      "Label: IN\n",
      "Label: RB\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: PRP\n",
      "Label: MD\n",
      "Label: None\n",
      "Label: None\n",
      "Label: DT\n",
      "Label: NNP\n",
      "Label: IN\n",
      "Label: NNP\n",
      "Label: Lemma('function.v.01.operate')\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: CC\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: NNP\n",
      "Label: IN\n",
      "Label: NNP\n",
      "Label: CC\n",
      "Label: DT\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: JJ\n",
      "Label: CC\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: IN\n",
      "Label: JJ\n",
      "Label: NNS\n",
      "Label: IN\n",
      "Label: MD\n",
      "Label: VB\n",
      "Label: Lemma('agree.v.01.agree')\n",
      "Label: JJ\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NNP\n",
      "Label: CC\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NNP\n",
      "Label: None\n",
      "Label: NNP\n",
      "Label: None\n",
      "Label: CC\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: DT\n",
      "Label: Lemma('idea.n.01.idea')\n",
      "Label: Lemma('here.r.02.here')\n",
      "Label: Lemma('be.v.02.be')\n",
      "Label: JJ\n",
      "Label: IN\n",
      "Label: Lemma('discharge.n.02.discharge')\n",
      "Label: CC\n",
      "Label: DT\n",
      "Label: MD\n",
      "Label: Lemma('stand.v.03.stand')\n",
      "Label: VB\n",
      "Label: Lemma('opposition.n.02.opposition')\n",
      "Label: TO\n",
      "Label: DT\n",
      "Label: Lemma('second.s.01.second')\n",
      "Label: Lemma('position.n.03.view')\n",
      "Label: None\n",
      "Label: Lemma('plato.n.01.Plato')\n",
      "Label: POS\n",
      "Label: Lemma('notion.n.02.notion')\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: Lemma('arousal.n.01.arousal')\n",
      "Label: IN\n",
      "Label: Lemma('emotion.n.01.emotion')\n",
      "Label: None\n",
      "Label: CC\n",
      "Label: IN\n",
      "Label: WP\n",
      "Label: Lemma('resource.n.02.resource')\n",
      "Label: VBD\n",
      "Label: Lemma('person.n.01.person')\n",
      "Label: Lemma('back.v.09.back_up')\n",
      "Label: PRP$\n",
      "Label: Lemma('creed.n.01.credo')\n",
      "Label: IN\n",
      "Label: Lemma('words.n.01.words')\n",
      "Label: None\n",
      "Label: IN\n",
      "Label: Lemma('downpour.n.01.torrent')\n",
      "Label: IN\n",
      "Label: Lemma('powerful.a.01.powerful')\n",
      "Label: Lemma('music.n.01.music')\n",
      "Label: None\n",
      "Label: EX\n",
      "Label: Lemma('exist.v.01.be')\n",
      "Label: Lemma('besides.r.02.also')\n",
      "Label: Lemma('more.r.01.more')\n",
      "Label: Lemma('basic.a.01.basic')\n",
      "Label: Lemma('problem.n.01.problem')\n",
      "Label: None\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: Lemma('be.v.01.be')\n",
      "Label: RB\n",
      "Label: JJ\n",
      "Label: IN\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: MD\n",
      "Label: Lemma('change.v.03.vary')\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: JJ\n",
      "Label: NNS\n",
      "Label: VBP\n",
      "Label: Lemma('allocate.v.01.allocate')\n",
      "Label: None\n",
      "Label: IN\n",
      "Label: JJ\n",
      "Label: CC\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: VBZ\n",
      "Label: Lemma('use.v.01.apply')\n",
      "Label: None\n",
      "Label: WRB\n",
      "Label: VBD\n",
      "Label: PRP\n",
      "Label: Lemma('prosecute.v.03.engage')\n",
      "Label: VB\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: FW\n",
      "Label: FW\n",
      "Label: None\n",
      "Label: Lemma('throw.v.01.throw')\n",
      "Label: JJ\n",
      "Label: NNS\n",
      "Label: TO\n",
      "Label: DT\n",
      "Label: NNS\n",
      "Label: CC\n",
      "Label: Lemma('promise.v.01.promise')\n",
      "Label: TO\n",
      "Label: Lemma('be.v.01.be')\n",
      "Label: JJ\n",
      "Label: NNS\n",
      "Label: RB\n",
      "Label: None\n",
      "Label: Lemma('express.v.02.express')\n",
      "Label: PRP$\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NNS\n",
      "Label: None\n",
      "Label: None\n",
      "Label: NNP\n",
      "Label: MD\n",
      "Label: Lemma('cant.v.01.tilt')\n",
      "Label: PRP$\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: CD\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: PRP\n",
      "Label: Lemma('lounge.v.01.lounge')\n",
      "Label: IN\n",
      "Label: PRP$\n",
      "Label: NNS\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: Lemma('indulge.v.03.indulge')\n",
      "Label: VB\n",
      "Label: DT\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: NN\n",
      "Label: NNS\n",
      "Label: IN\n",
      "Label: JJ\n",
      "Label: CD\n",
      "Label: NNS\n",
      "Label: VBG\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: Lemma('long.a.01.long')\n",
      "Label: Lemma('weekend.n.01.weekend')\n",
      "Label: Lemma('enable.v.01.enable')\n",
      "Label: Lemma('many.a.01.many')\n",
      "Label: TO\n",
      "Label: Lemma('escape.v.05.get_away')\n",
      "Label: IN\n",
      "Label: Lemma('home.r.01.home')\n",
      "Label: IN\n",
      "Label: Lemma('three.s.01.three')\n",
      "Label: CC\n",
      "Label: Lemma('four.s.01.four')\n",
      "Label: Lemma('day.n.01.day')\n",
      "Label: several.s.01\n",
      "Label: Lemma('time.n.01.time')\n",
      "Label: DT\n",
      "Label: Lemma('year.n.01.year')\n",
      "Label: None\n",
      "Label: Lemma('berlin.n.01.Berlin')\n",
      "Label: POS\n",
      "Label: Lemma('resilience.n.01.resilience')\n",
      "Label: Lemma('be.v.01.be')\n",
      "Label: Lemma('amazing.s.01.amazing')\n",
      "Label: None\n",
      "Label: CC\n",
      "Label: IN\n",
      "Label: PRP\n",
      "Label: VB\n",
      "Label: VB\n",
      "Label: Lemma('rent.v.04.hire')\n",
      "Label: PRP$\n",
      "Label: Lemma('labor.n.02.labor')\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: Lemma('west.n.01.West')\n",
      "Label: DT\n",
      "Label: Lemma('struggle.n.01.struggle')\n",
      "Label: MD\n",
      "Label: Lemma('be.v.01.be')\n",
      "Label: Lemma('difficult.a.01.hard')\n",
      "Label: Lemma('indeed.r.01.indeed')\n",
      "Label: None\n",
      "Label: None\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: PRP\n",
      "Label: have.v.00\n",
      "Label: VB\n",
      "Label: Lemma('talk.v.01.talk')\n",
      "Label: TO\n",
      "Label: PRP\n",
      "Label: IN\n",
      "Label: PRP\n",
      "Label: Lemma('fill.v.04.take')\n",
      "Label: PRP$\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: NNS\n",
      "Label: None\n",
      "Label: PRP\n",
      "Label: Lemma('indicate.v.02.indicate')\n",
      "Label: PRP\n",
      "Label: VBD\n",
      "Label: Lemma('disgust.v.02.sicken')\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NNS\n",
      "Label: NNS\n",
      "Label: Lemma('use.v.01.employ')\n",
      "Label: TO\n",
      "Label: Lemma('survive.v.01.live')\n",
      "Label: CC\n",
      "Label: Lemma('trade.v.01.trade')\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: Lemma('assume.v.03.take_on')\n",
      "Label: DT\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: DT\n",
      "Label: Lemma('prove.v.02.prove')\n",
      "Label: RB\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NNP\n",
      "Label: Lemma('be.v.01.be')\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: RB\n",
      "Label: PRP\n",
      "Label: Lemma('walk.v.01.walk')\n",
      "Label: IN\n",
      "Label: RB\n",
      "Label: TO\n",
      "Label: NNP\n",
      "Label: None\n",
      "Label: DT\n",
      "Label: RB\n",
      "Label: RBR\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: DT\n",
      "Label: VBZ\n",
      "Label: Lemma('not.r.01.not')\n",
      "Label: Lemma('extend.v.04.extend')\n",
      "Label: VB\n",
      "Label: Lemma('anticipated.s.01.anticipated')\n",
      "Label: Lemma('degree.n.01.level')\n",
      "Label: IN\n",
      "Label: Lemma('gross_national_product.n.01.GNP')\n",
      "Label: None\n",
      "Label: Lemma('however.r.01.however')\n",
      "Label: None\n",
      "Label: RB\n",
      "Label: DT\n",
      "Label: Lemma('current.a.01.current')\n",
      "Label: Lemma('degree.n.01.level')\n",
      "Label: IN\n",
      "Label: Lemma('gross_national_product.n.01.GNP')\n",
      "Label: Lemma('affect.v.01.affect')\n",
      "Label: DT\n",
      "Label: Lemma('populace.n.01.public')\n",
      "Label: Lemma('pressure.n.02.pressure')\n",
      "Label: IN\n",
      "Label: Lemma('wage.n.01.wage')\n",
      "Label: Lemma('monetary_value.n.01.price')\n",
      "Label: Lemma('addition.n.03.increase')\n",
      "Label: None\n",
      "Label: DT\n",
      "Label: JJ\n",
      "Label: NNS\n",
      "Label: VBP\n",
      "Label: RB\n",
      "Label: Lemma('occasion.v.01.occasion')\n",
      "Label: IN\n",
      "Label: JJ\n",
      "Label: NNS\n",
      "Label: RB\n",
      "Label: None\n",
      "Label: CC\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: NNS\n",
      "Label: TO\n",
      "Label: Lemma('have.v.01.have')\n",
      "Label: NNS\n",
      "Label: PRP\n",
      "Label: MD\n",
      "Label: Lemma('blame.v.02.blame')\n",
      "Label: None\n",
      "Label: Lemma('distrust.v.01.distrust')\n",
      "Label: None\n",
      "Label: Lemma('denounce.v.01.denounce')\n",
      "Label: None\n",
      "Label: CC\n",
      "Label: RB\n",
      "Label: Lemma('hate.v.01.hate')\n",
      "Label: None\n",
      "Label: PRP$\n",
      "Label: NN\n",
      "Label: Lemma('be.v.02.be')\n",
      "Label: NNP\n",
      "Label: None\n",
      "Label: PRP\n",
      "Label: MD\n",
      "Label: n't.r.00\n",
      "Label: VB\n",
      "Label: Lemma('laugh.v.01.laugh')\n",
      "Label: None\n",
      "Label: NNS\n",
      "Label: None\n",
      "Label: DT\n",
      "Label: RB\n",
      "Label: CC\n",
      "Label: RB\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: VBP\n",
      "Label: RB\n",
      "Label: Lemma('compare.v.03.equate')\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: NN\n",
      "Label: NNS\n",
      "Label: None\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: Lemma('see.v.05.view')\n",
      "Label: IN\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: CD\n",
      "Label: NNS\n",
      "Label: IN\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: NN\n",
      "Label: CC\n",
      "Label: Lemma('curse.v.01.curse')\n",
      "Label: None\n",
      "Label: NN\n",
      "Label: Lemma('state.v.01.say')\n",
      "Label: None\n",
      "Label: NNP\n",
      "Label: VB\n",
      "Label: None\n",
      "Label: None\n",
      "Label: UH\n",
      "Label: None\n",
      "Label: IN\n",
      "Label: VBZ\n",
      "Label: Lemma('complete.s.05.over')\n",
      "Label: Lemma('nowadays.r.01.now')\n",
      "Label: None\n",
      "Label: NNP\n",
      "Label: Lemma('act.v.03.play')\n",
      "Label: PRP\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: CC\n",
      "Label: NNP\n",
      "Label: None\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NNP\n",
      "Label: None\n",
      "Label: Lemma('make.v.02.make')\n",
      "Label: PRP\n",
      "Label: DT\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: RB\n",
      "Label: DT\n",
      "Label: NNS\n",
      "Label: Lemma('tell.v.02.tell')\n",
      "Label: PRP\n",
      "Label: None\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: WP\n",
      "Label: PRP\n",
      "Label: Lemma('study.v.02.study')\n",
      "Label: NN\n",
      "Label: Lemma('steer.v.01.steer')\n",
      "Label: PRP\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NNP\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: NNP\n",
      "Label: Lemma('quote.v.01.quote')\n",
      "Label: NNP\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NNP\n",
      "Label: NN\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: Lemma('allege.v.01.say')\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NNP\n",
      "Label: VBZ\n",
      "Label: Lemma('become.v.01.become')\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: CC\n",
      "Label: CC\n",
      "Label: None\n",
      "Label: VBZ\n",
      "Label: RB\n",
      "Label: Lemma('wish.v.02.wish')\n",
      "Label: VB\n",
      "Label: VB\n",
      "Label: JJ\n",
      "Label: VB\n",
      "Label: NN\n",
      "Label: WDT\n",
      "Label: Lemma('be.v.01.be')\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: JJ\n",
      "Label: TO\n",
      "Label: PRP$\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: PRP\n",
      "Label: Lemma('tend.v.01.tend')\n",
      "Label: VB\n",
      "Label: Lemma('shy_away_from.v.01.shy_away_from')\n",
      "Label: DT\n",
      "Label: JJ\n",
      "Label: CC\n",
      "Label: NN\n",
      "Label: NNS\n",
      "Label: IN\n",
      "Label: RB\n",
      "Label: Lemma('make.v.02.make')\n",
      "Label: NNP\n",
      "Label: NN\n",
      "Label: NNS\n",
      "Label: JJ\n",
      "Label: None\n",
      "Label: None\n",
      "Label: IN\n",
      "Label: Lemma('affirm.v.02.affirm')\n",
      "Label: DT\n",
      "Label: PRP\n",
      "Label: VBP\n",
      "Label: Lemma('already.r.01.already')\n",
      "Label: Lemma('take.v.01.take')\n",
      "Label: DT\n",
      "Label: Lemma('decisive.a.01.decisive')\n",
      "Label: Lemma('measure.n.01.step')\n",
      "Label: VB\n",
      "Label: Lemma('interrupt.v.04.break')\n",
      "Label: DT\n",
      "Label: Lemma('deadlock.n.01.deadlock')\n",
      "Label: IN\n",
      "Label: WDT\n",
      "Label: Lemma('person.n.01.person')\n",
      "Label: POS\n",
      "Label: Lemma('attempt.n.01.attempt')\n",
      "Label: TO\n",
      "Label: Lemma('explicate.v.02.formulate')\n",
      "Label: such.s.00\n",
      "Label: DT\n",
      "Label: Lemma('theology.n.01.theology')\n",
      "Label: VBZ\n",
      "Label: Lemma('leave.v.07.lead')\n",
      "Label: None\n",
      "Label: DT\n",
      "Label: Lemma('inhabitant.n.01.dweller')\n",
      "Label: IN\n",
      "Label: NN\n",
      "Label: Lemma('be.v.01.be')\n",
      "Label: Lemma('last.a.02.last')\n",
      "Label: TO\n",
      "Label: Lemma('learn.v.02.hear')\n",
      "Label: VB\n",
      "Label: DT\n",
      "Label: Lemma('new.a.01.new')\n",
      "Label: Lemma('remedy.n.02.cure')\n",
      "Label: None\n",
      "Label: DT\n",
      "Label: Lemma('slow.a.01.slow')\n",
      "Label: TO\n",
      "Label: Lemma('announce.v.01.announce')\n",
      "Label: TO\n",
      "Label: PRP$\n",
      "Label: Lemma('neighbor.n.01.neighbor')\n",
      "Label: PRP$\n",
      "Label: Lemma('pressing.s.01.urgent')\n",
      "Label: Lemma('distress.n.02.distress')\n",
      "Label: None\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: WP\n",
      "Label: Lemma('travel.v.01.go')\n",
      "Label: DT\n",
      "Label: Lemma('farthest.r.01.farthest')\n",
      "Label: TO\n",
      "Label: Lemma('trade.v.01.trade')\n",
      "Label: None\n",
      "Label: CC\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: great.s.00\n",
      "Label: Lemma('trouble.n.04.difficulty')\n",
      "Label: IN\n",
      "Label: JJ\n",
      "Label: JJ\n",
      "Label: Lemma('get_across.v.01.put_over')\n",
      "Label: DT\n",
      "Label: Lemma('mind.n.06.idea')\n",
      "Label: CC\n",
      "Label: Lemma('get.v.03.get')\n",
      "Label: Lemma('people.n.01.people')\n",
      "Label: TO\n",
      "Label: Lemma('join.v.01.join')\n",
      "Label: PRP\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: Lemma('concerted.s.01.cooperative')\n",
      "Label: Lemma('attempt.n.01.effort')\n",
      "Label: None\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: Lemma('composer.n.01.composer')\n",
      "Label: None\n",
      "Label: Lemma('lincoln.n.01.Abraham_Lincoln')\n",
      "Label: Lemma('emerge.v.03.emerge')\n",
      "Label: RB\n",
      "Label: DT\n",
      "Label: Lemma('embodiment.n.01.incarnation')\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: Lemma('national.a.01.national')\n",
      "Label: Lemma('fundamental_law.n.01.constitution')\n",
      "Label: None\n",
      "Label: PRP\n",
      "Label: Lemma('besides.r.02.also')\n",
      "Label: Lemma('hope.v.02.hope')\n",
      "Label: IN\n",
      "Label: PRP\n",
      "Label: MD\n",
      "Label: Lemma('make.v.01.do')\n",
      "Label: VB\n",
      "Label: IN\n",
      "Label: Lemma('reduce.v.01.reduce')\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: Lemma('idea.n.01.idea')\n",
      "Label: None\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: Lemma('bureaucracy.n.01.bureaucracy')\n",
      "Label: None\n",
      "Label: RB\n",
      "Label: PRP\n",
      "Label: Lemma('be.v.01.be')\n",
      "Label: IN\n",
      "Label: PRP$\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: IN\n",
      "Label: Lemma('be.v.01.be')\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: PRP\n",
      "Label: RB\n",
      "Label: None\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: None\n",
      "Label: UH\n",
      "Label: None\n",
      "Label: VBP\n",
      "Label: Lemma('forgive.v.01.forgive')\n",
      "Label: PRP\n",
      "Label: None\n",
      "Label: None\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: VBZ\n",
      "Label: Lemma('report.v.02.report')\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: CD\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: PRP$\n",
      "Label: Lemma('bel_canto.n.01.bel_canto')\n",
      "Label: Lemma('expressive_style.n.01.style')\n",
      "Label: Lemma('establish.v.05.give')\n",
      "Label: DT\n",
      "Label: Lemma('performance.n.01.performance')\n",
      "Label: DT\n",
      "Label: Lemma('particular.s.01.special')\n",
      "Label: Lemma('eminence.n.01.distinction')\n",
      "Label: None\n",
      "Label: PRP\n",
      "Label: hold.v.1;2\n",
      "Label: DT\n",
      "Label: Lemma('control.n.09.control')\n",
      "Label: WRB\n",
      "Label: PRP\n",
      "Label: VBD\n",
      "Label: Lemma('be.v.03.be')\n",
      "Label: None\n",
      "Label: NNP\n",
      "Label: Lemma('write.v.02.write')\n",
      "Label: None\n",
      "Label: None\n",
      "Label: EX\n",
      "Label: Lemma('be.v.01.be')\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: Lemma('try.v.01.try')\n",
      "Label: TO\n",
      "Label: Lemma('make.v.02.make')\n",
      "Label: NN\n",
      "Label: TO\n",
      "Label: DT\n",
      "Label: NNP\n",
      "Label: RB\n",
      "Label: JJ\n",
      "Label: CC\n",
      "Label: JJ\n",
      "Label: IN\n",
      "Label: NNS\n",
      "Label: MD\n",
      "Label: RB\n",
      "Label: Lemma('know.v.01.know')\n",
      "Label: IN\n",
      "Label: NN\n",
      "Label: VBZ\n",
      "Label: Lemma('happen.v.01.happen')\n",
      "Label: None\n",
      "Label: None\n",
      "Label: Lemma('possibly.r.01.perhaps')\n",
      "Label: DT\n",
      "Label: Lemma('group.n.01.group')\n",
      "Label: WP\n",
      "Label: MD\n",
      "Label: Lemma('be.v.01.be')\n",
      "Label: DT\n",
      "Label: Lemma('unhappy.a.01.unhappy')\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: Lemma('news.n.02.news')\n",
      "Label: IN\n",
      "Label: Lemma('person.n.01.person')\n",
      "Label: Lemma('probably.r.01.probably')\n",
      "Label: MD\n",
      "Label: Lemma('sit_out.v.01.sit_out')\n",
      "Label: Lemma('most.a.02.most')\n",
      "Label: JJ\n",
      "Label: DT\n",
      "Label: Lemma('series.n.01.series')\n",
      "Label: Lemma('be.v.02.be')\n",
      "Label: Lemma('person.n.01.person')\n",
      "Label: None\n",
      "Label: WP\n",
      "Label: VBD\n",
      "Label: Lemma('beat.v.01.beat')\n",
      "Label: IN\n",
      "Label: Lemma('person.n.01.person')\n",
      "Label: Lemma('twice.r.01.twice')\n",
      "Label: Lemma('last.s.01.last')\n",
      "Label: Lemma('season.n.01.season')\n",
      "Label: IN\n",
      "Label: Lemma('dramatic.a.01.dramatic')\n",
      "Label: Lemma('homer.n.01.home_run')\n",
      "Label: None\n",
      "Label: IN\n",
      "Label: PRP\n",
      "Label: VB\n",
      "Label: VB\n",
      "Label: Lemma('take.v.09.take')\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: PRP\n",
      "Label: MD\n",
      "Label: RB\n",
      "Label: Lemma('take.v.09.take')\n",
      "Label: DT\n",
      "Label: JJ\n",
      "Label: CD\n",
      "Label: None\n",
      "Label: DT\n",
      "Label: Lemma('pale.s.04.pale')\n",
      "Label: Lemma('blob.n.01.blob')\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: Lemma('woman.n.01.woman')\n",
      "Label: Lemma('disappear.v.01.disappear')\n",
      "Label: None\n",
      "Label: None\n",
      "Label: WP\n",
      "Label: RB\n",
      "Label: None\n",
      "Label: None\n",
      "Label: None\n",
      "Label: DT\n",
      "Label: JJ\n",
      "Label: CD\n",
      "Label: NNS\n",
      "Label: VBD\n",
      "Label: Lemma('crash.v.01.crash')\n",
      "Label: None\n",
      "Label: None\n",
      "Label: PRP\n",
      "Label: Lemma('state.v.01.say')\n",
      "Label: None\n",
      "Label: DT\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: WDT\n",
      "Label: Lemma('lend.v.01.contribute')\n",
      "Label: RB\n",
      "Label: TO\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NNP\n",
      "Label: None\n",
      "Label: RB\n",
      "Label: IN\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: Lemma('be.v.02.be')\n",
      "Label: DT\n",
      "Label: JJ\n",
      "Label: NN\n",
      "Label: WDT\n",
      "Label: VBD\n",
      "Label: VBN\n",
      "Label: Lemma('lay_down.v.01.establish')\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NNPS\n",
      "Label: IN\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: DT\n",
      "Label: None\n",
      "Label: NNP\n",
      "Label: None\n",
      "Label: Lemma('read.v.02.say')\n",
      "Label: IN\n",
      "Label: PRP\n",
      "Label: None\n",
      "Label: Lemma('deliver.v.01.deliver')\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: DT\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: WDT\n",
      "Label: IN\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: NN\n",
      "Label: CC\n",
      "Label: NN\n",
      "Label: IN\n",
      "Label: NN\n",
      "Label: None\n",
      "Label: Lemma('be.v.01.be')\n",
      "Label: RB\n",
      "Label: JJ\n",
      "Label: None\n",
      "Label: None\n",
      "Label: CC\n",
      "Label: NNP\n",
      "Label: None\n",
      "Label: NNP\n",
      "Label: None\n"
     ]
    }
   ],
   "source": [
    "for sent in sent_list:\n",
    "    # print(\"\\nlen:\", len(sent))\n",
    "    l = len(sent)\n",
    "    rn = random.randint(0, l-1)\n",
    "\n",
    "    for word in sent:\n",
    "        # word, \"| Label:\", word.label(), \"| Leaves:\", word.leaves()[0], \"| PoS Tag:\", word.pos()\n",
    "        print(\"Label:\", word.label())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'tagged_sents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/paolobonicco/Projects/nlp-UniTO-2021-22/Radicioni/es2_wsd/paolo_wds.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/paolobonicco/Projects/nlp-UniTO-2021-22/Radicioni/es2_wsd/paolo_wds.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sent_list \u001b[39m=\u001b[39m sent_list\u001b[39m.\u001b[39;49mtagged_sents(tag\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mboth\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m# Lista di frasi estratte, tipo: SemCor --> Tree\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/paolobonicco/Projects/nlp-UniTO-2021-22/Radicioni/es2_wsd/paolo_wds.ipynb#X52sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m cleaned_sent_list \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/paolobonicco/Projects/nlp-UniTO-2021-22/Radicioni/es2_wsd/paolo_wds.ipynb#X52sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m sent_list:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'tagged_sents'"
     ]
    }
   ],
   "source": [
    "sent_list = sent_list.tagged_sents(tag=\"both\") # Lista di frasi estratte, tipo: SemCor --> Tree\n",
    "\n",
    "cleaned_sent_list = []\n",
    "\n",
    "for sent in sent_list:\n",
    "    sent.label()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metodi utili per classe Tree() di nltk\n",
    "<a href=\"https://www.nltk.org/_modules/nltk/tree.html\">Link documentazione</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in sent_list:\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT')]\n",
      "[('Fulton', 'NNP'), ('County', 'NNP'), ('Grand', 'NNP'), ('Jury', 'NNP')]\n",
      "[('said', 'VB')]\n",
      "[('Friday', 'NN')]\n",
      "[('an', 'DT')]\n",
      "[('investigation', 'NN')]\n",
      "[('of', 'IN')]\n",
      "[('Atlanta', 'NN')]\n",
      "[(\"'s\", 'POS')]\n",
      "[('recent', 'JJ')]\n",
      "[('primary', 'NN'), ('election', 'NN')]\n",
      "[('produced', 'VB')]\n",
      "[('``', None)]\n",
      "[('no', 'DT')]\n",
      "[('evidence', 'NN')]\n",
      "[(\"''\", None)]\n",
      "[('that', 'IN')]\n",
      "[('any', 'DT')]\n",
      "[('irregularities', 'NN')]\n",
      "[('took', 'VB'), ('place', 'VB')]\n",
      "[('.', None)]\n"
     ]
    }
   ],
   "source": [
    "tag_sent = semcor.tagged_sents(tag='both')[0]\n",
    "\n",
    "for el in tag_sent:\n",
    "    print(el.pos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT\n",
      "Lemma('group.n.01.group')\n",
      "Lemma('state.v.01.say')\n",
      "Lemma('friday.n.01.Friday')\n",
      "DT\n",
      "Lemma('probe.n.01.investigation')\n",
      "IN\n",
      "Lemma('atlanta.n.01.Atlanta')\n",
      "POS\n",
      "Lemma('late.s.03.recent')\n",
      "Lemma('primary.n.01.primary_election')\n",
      "Lemma('produce.v.04.produce')\n",
      "None\n",
      "DT\n",
      "Lemma('evidence.n.01.evidence')\n",
      "None\n",
      "IN\n",
      "DT\n",
      "Lemma('abnormality.n.04.irregularity')\n",
      "Lemma('happen.v.01.take_place')\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for el in tag_sent:\n",
    "    print(el.label())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The']\n",
      "['Fulton', 'County', 'Grand', 'Jury']\n",
      "['said']\n",
      "['Friday']\n",
      "['an']\n",
      "['investigation']\n",
      "['of']\n",
      "['Atlanta']\n",
      "[\"'s\"]\n",
      "['recent']\n",
      "['primary', 'election']\n",
      "['produced']\n",
      "['``']\n",
      "['no']\n",
      "['evidence']\n",
      "[\"''\"]\n",
      "['that']\n",
      "['any']\n",
      "['irregularities']\n",
      "['took', 'place']\n",
      "['.']\n"
     ]
    }
   ],
   "source": [
    "for el in tag_sent:\n",
    "    print(el.leaves())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puliamo le frasi rimuovendo i termini senza un sysnet associato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sent(sent):\n",
    "    cleaned_sent = []\n",
    "    for el in sent:\n",
    "        if el[1] == 'NN':\n",
    "            cleaned_sent.append(el[0])\n",
    "    return cleaned_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approccio alternativo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  !!!! Non usare Venv perchÃ¨ non riesco ad installare lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import xml.etree.ElementTree as eT\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree as exml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/semcor3.0/brown1/tagfiles/br-a01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(path):\n",
    "    '''\n",
    "    It parses the SemCor corpus, which has been annotated by hand on WordNet synsets by Rada Mihalcea and her team.\n",
    "    In order:\n",
    "        1) Load XML file\n",
    "        2) Took all the tags \"s\"\n",
    "        3) Extract the sentence\n",
    "        4) Select the words to disambiguate (select only the needed ones) with total number of senses >= 2\n",
    "        5) Extract Golden annotated sense from WSN\n",
    "    Args:\n",
    "        path: the path to the XML file (Brown Corpus)\n",
    "    Returns:\n",
    "        [(sentence, [(word, gold)])]\n",
    "    '''\n",
    "\n",
    "    with open(path, 'r') as fileXML:\n",
    "        data = fileXML.read()\n",
    "\n",
    "        # fixing XML's bad formatting\n",
    "        data = data.replace('\\n', '')\n",
    "        replacer = re.compile(\"=([\\w|:|\\-|$|(|)|']*)\")\n",
    "        data = replacer.sub(r'=\"\\1\"', data)\n",
    "\n",
    "        result = []\n",
    "        try:\n",
    "            root = exml.XML(data)\n",
    "            paragraphs = root.findall(\"./context/p\")\n",
    "            sentences = []\n",
    "            for p in paragraphs:\n",
    "                sentences.extend(p.findall(\"./s\"))\n",
    "            for sentence in sentences:\n",
    "                words = sentence.findall('wf')\n",
    "                sent = \"\"\n",
    "                tuple_list = []\n",
    "                for word in words:\n",
    "                    w = word.text\n",
    "                    pos = word.attrib['pos']\n",
    "                    sent = sent + w + ' '\n",
    "                    if pos_validity(pos=pos, text=w, word=word):\n",
    "                        sense = word.attrib['wnsn']\n",
    "                        t = (w, sense)\n",
    "                        tuple_list.append(t)\n",
    "                result.append((sent, tuple_list))\n",
    "        except Exception as e:\n",
    "            raise NameError('xml: ' + str(e))\n",
    "    return result\n",
    "\n",
    "def pos_validity(pos, text, word):\n",
    "    \"\"\"Auxiliary function for the parse_xml\n",
    "    Args:\n",
    "        pos:\n",
    "        text:\n",
    "        word: ambiguous word (with more that 1 sense)\n",
    "    Returns:\n",
    "        boolean: True if the word is valid and false otherwise\n",
    "    \"\"\"\n",
    "    return pos == 'NN' and '_' not in text and len(wn.synsets(text)) > 1 and 'wnsn' in word.attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"The Fulton_County_Grand_Jury said Friday an investigation of Atlanta 's recent primary_election produced no evidence that any irregularities took_place \",\n",
       "  [('investigation', '1'),\n",
       "   ('Atlanta', '1'),\n",
       "   ('evidence', '1'),\n",
       "   ('irregularities', '1')]),\n",
       " ('The jury further said in term end presentments that the City_Executive_Committee which had over-all charge of the election deserves the praise and thanks of the City_of_Atlanta for the manner in which the election was conducted ',\n",
       "  [('jury', '1'),\n",
       "   ('term', '2'),\n",
       "   ('end', '2'),\n",
       "   ('presentments', '1'),\n",
       "   ('charge', '6'),\n",
       "   ('election', '1'),\n",
       "   ('praise', '1'),\n",
       "   ('thanks', '1'),\n",
       "   ('manner', '1'),\n",
       "   ('election', '1')]),\n",
       " ('The September October term jury had been charged by Fulton Superior_Court_Judge_Durwood_Pye to investigate reports of possible irregularities in the hard-fought primary which was won by Mayor-nominate_Ivan_Allen_Jr. ',\n",
       "  [('term', '2'),\n",
       "   ('jury', '1'),\n",
       "   ('reports', '3'),\n",
       "   ('irregularities', '1'),\n",
       "   ('primary', '1')]),\n",
       " ('Only a relative handful of such reports was received the jury said considering the widespread interest in the election the number of voters and the size of_this city ',\n",
       "  [('handful', '1'),\n",
       "   ('reports', '3'),\n",
       "   ('jury', '1'),\n",
       "   ('interest', '1'),\n",
       "   ('election', '1'),\n",
       "   ('number', '2'),\n",
       "   ('size', '1'),\n",
       "   ('city', '1')]),\n",
       " (\"The jury said it did find that many_of Georgia 's registration and election laws are outmoded or inadequate and often ambiguous \",\n",
       "  [('jury', '1'),\n",
       "   ('Georgia', '1'),\n",
       "   ('registration', '1'),\n",
       "   ('election', '1'),\n",
       "   ('laws', '2')]),\n",
       " ('It recommended that Fulton legislators act to have these laws studied and revised to the end of modernizing and improving them ',\n",
       "  [('laws', '2'), ('end', '4')]),\n",
       " ('The grand_jury commented on a number of other topics among them the Atlanta and Fulton_County purchasing_departments which it said are well operated and follow generally accepted practices which inure to the best interest of both governments ',\n",
       "  [('number', '1'),\n",
       "   ('topics', '2'),\n",
       "   ('Atlanta', '1'),\n",
       "   ('practices', '1'),\n",
       "   ('interest', '2'),\n",
       "   ('governments', '1')]),\n",
       " ('However the jury said it believes these two offices should be combined to achieve greater efficiency and reduce the cost of administration ',\n",
       "  [('jury', '1'),\n",
       "   ('offices', '2'),\n",
       "   ('efficiency', '2'),\n",
       "   ('cost', '1'),\n",
       "   ('administration', '1')]),\n",
       " ('The City_Purchasing_Department the jury said is lacking in experienced clerical personnel as a result of city personnel policies ',\n",
       "  [('jury', '1'),\n",
       "   ('personnel', '1'),\n",
       "   ('result', '1'),\n",
       "   ('city', '2'),\n",
       "   ('personnel', '1'),\n",
       "   ('policies', '1')]),\n",
       " ('It urged that the city take steps to remedy this problem ',\n",
       "  [('city', '2'), ('steps', '1'), ('problem', '2')]),\n",
       " (\"Implementation of Georgia 's automobile title law was also recommended by the outgoing jury \",\n",
       "  [('Implementation', '1'),\n",
       "   ('Georgia', '1'),\n",
       "   ('automobile', '1'),\n",
       "   ('title', '5'),\n",
       "   ('law', '2'),\n",
       "   ('jury', '1')]),\n",
       " ('It urged that the next Legislature provide enabling funds and re-set the effective date so_that an orderly implementation of the law may be effected ',\n",
       "  [('funds', '1'), ('date', '1'), ('implementation', '1'), ('law', '2')]),\n",
       " (\"The grand_jury took_a_swipe_at the State_Welfare_Department 's handling of federal funds granted for child_welfare_services in foster_homes \",\n",
       "  [('handling', '1'), ('funds', '1')]),\n",
       " ('This is one of the major items in the Fulton_County general assistance program the jury said but the State_Welfare_Department has seen_fit to distribute these funds through the welfare departments of all the counties in the state with the exception of Fulton_County which receives none of_this money ',\n",
       "  [('items', '4'),\n",
       "   ('assistance', '1'),\n",
       "   ('program', '1'),\n",
       "   ('jury', '1'),\n",
       "   ('funds', '1'),\n",
       "   ('welfare', '1'),\n",
       "   ('departments', '1'),\n",
       "   ('counties', '1'),\n",
       "   ('state', '1'),\n",
       "   ('exception', '1'),\n",
       "   ('money', '1')]),\n",
       " ('The jurors said they realize a proportionate distribution of these funds might disable this program in our less populous counties ',\n",
       "  [('distribution', '2'),\n",
       "   ('funds', '1'),\n",
       "   ('program', '1'),\n",
       "   ('counties', '1')]),\n",
       " ('Nevertheless we feel that in_the_future Fulton_County should receive some portion of these available funds the jurors said ',\n",
       "  [('portion', '3'), ('funds', '1')]),\n",
       " ('Failure to do this will continue to place a disproportionate burden on Fulton taxpayers ',\n",
       "  [('Failure', '1'), ('burden', '1')]),\n",
       " (\"The jury also commented on the Fulton ordinary 's court which has been under_fire for its practices in the appointment of appraisers guardians and administrators and the awarding of fees and compensation \",\n",
       "  [('jury', '1'),\n",
       "   ('ordinary', '2'),\n",
       "   ('court', '1'),\n",
       "   ('practices', '1'),\n",
       "   ('appointment', '1'),\n",
       "   ('appraisers', '1'),\n",
       "   ('administrators', '1'),\n",
       "   ('awarding', '1'),\n",
       "   ('fees', '1'),\n",
       "   ('compensation', '1')]),\n",
       " ('The jury said it found the court has incorporated into its operating_procedures the recommendations of two previous grand_juries the Atlanta_Bar_Association and an interim citizens_committee ',\n",
       "  [('jury', '1'), ('court', '1'), ('recommendations', '1')]),\n",
       " (\"These actions should serve to protect in_fact and in_effect the court 's wards from undue costs and its appointed and elected servants from unmeritorious criticisms the jury said \",\n",
       "  [('actions', '1'),\n",
       "   ('court', '1'),\n",
       "   ('wards', '1'),\n",
       "   ('costs', '1'),\n",
       "   ('servants', '1'),\n",
       "   ('criticisms', '1'),\n",
       "   ('jury', '1')]),\n",
       " (\"Regarding Atlanta 's new million dollar airport the jury recommended that when the new management takes_charge Jan. 1 the airport be operated in a manner that will eliminate political influences \",\n",
       "  [('Atlanta', '1'),\n",
       "   ('dollar', '1'),\n",
       "   ('jury', '1'),\n",
       "   ('management', '2'),\n",
       "   ('manner', '1'),\n",
       "   ('influences', '1')]),\n",
       " ('The jury did not elaborate but it added that there should be periodic surveillance of the pricing practices of the concessionaires for the purpose of keeping the prices reasonable ',\n",
       "  [('jury', '1'),\n",
       "   ('pricing', '1'),\n",
       "   ('practices', '1'),\n",
       "   ('purpose', '1'),\n",
       "   ('prices', '2')]),\n",
       " ('On other matters the jury recommended that ',\n",
       "  [('matters', '2'), ('jury', '1')]),\n",
       " ('Four additional deputies be employed at the Fulton_County_Jail and a doctor medical_intern or extern be employed for night and weekend duty at the jail ',\n",
       "  [('deputies', '2'),\n",
       "   ('doctor', '1'),\n",
       "   ('night', '1'),\n",
       "   ('weekend', '1'),\n",
       "   ('duty', '2'),\n",
       "   ('jail', '1')]),\n",
       " ('Fulton legislators work with city officials to pass enabling_legislation that will permit the establishment of a fair and equitable pension plan for city employes ',\n",
       "  [('city', '2'),\n",
       "   ('officials', '1'),\n",
       "   ('establishment', '1'),\n",
       "   ('pension', '1'),\n",
       "   ('plan', '1'),\n",
       "   ('city', '2'),\n",
       "   ('employes', '1')]),\n",
       " (\"The jury praised the administration and operation of the Atlanta Police_Department the Fulton_Tax_Commissioner_'s_Office the Bellwood and Alpharetta prison_farms Grady_Hospital and the Fulton_Health_Department \",\n",
       "  [('jury', '1'),\n",
       "   ('administration', '1'),\n",
       "   ('operation', '1'),\n",
       "   ('Atlanta', '1')]),\n",
       " ('Mayor_William_B._Hartsfield filed suit for divorce from his wife Pearl_Williams_Hartsfield in Fulton_Superior_Court Friday ',\n",
       "  [('suit', '2'), ('divorce', '1')]),\n",
       " ('His petition charged mental cruelty ',\n",
       "  [('petition', '1'), ('cruelty', '2')]),\n",
       " ('The couple was married Aug. 2 1913 ', [('couple', '2')]),\n",
       " ('They have a son William_Berry_Jr. and a daughter Mrs._J._M._Cheshire of Griffin ',\n",
       "  [('son', '1')]),\n",
       " ('Attorneys for the mayor said that an amicable property_settlement has been agreed_upon ',\n",
       "  []),\n",
       " (\"The petition listed the mayor 's occupation as attorney and his age as 71 \",\n",
       "  [('petition', '1'), ('occupation', '1'), ('age', '1')]),\n",
       " (\"It listed his wife 's age as 74 and place_of_birth as Opelika_,_Ala. \",\n",
       "  [('age', '1')]),\n",
       " ('The petition said that the couple has not lived together as man_and_wife for more than a year ',\n",
       "  [('petition', '1'), ('couple', '2'), ('year', '1')]),\n",
       " ('The Hartsfield home is at 637 E._Pelham_Rd._NE ', [('home', '2')]),\n",
       " (\"Henry_L._Bowden was listed on the petition as the mayor 's attorney \",\n",
       "  [('petition', '1')]),\n",
       " ('Hartsfield has been mayor of Atlanta with exception of one brief interlude since 1937 ',\n",
       "  [('Atlanta', '1'), ('exception', '1'), ('interlude', '1')]),\n",
       " ('His political career goes_back to his election to city_council in 1923 ',\n",
       "  [('career', '1'), ('election', '1')]),\n",
       " (\"The mayor 's present term_of_office expires Jan. 1 \", []),\n",
       " ('He will be succeeded by Ivan_Allen_Jr. who became a candidate in the Sept. 13 primary after Mayor_Hartsfield announced that he would not run for reelection ',\n",
       "  [('candidate', '1'), ('primary', '1')]),\n",
       " (\"Georgia Republicans are getting strong encouragement to enter a candidate in the 1962 governor_'s_race a top official said Wednesday \",\n",
       "  [('Georgia', '1'),\n",
       "   ('Republicans', '1'),\n",
       "   ('encouragement', '2'),\n",
       "   ('candidate', '1'),\n",
       "   ('official', '1')]),\n",
       " ('Robert_Snodgrass state GOP chairman said a meeting held Tuesday night in Blue_Ridge brought enthusiastic responses from the audience ',\n",
       "  [('state', '3'),\n",
       "   ('chairman', '1'),\n",
       "   ('meeting', '1'),\n",
       "   ('night', '1'),\n",
       "   ('responses', '4'),\n",
       "   ('audience', '1')]),\n",
       " ('State_Party_Chairman_James_W._Dorsey added that enthusiasm was picking_up for a state rally to be held Sept. 8 in Savannah at which newly elected Texas Sen._John_Tower will be the featured speaker ',\n",
       "  [('enthusiasm', '3'),\n",
       "   ('state', '1'),\n",
       "   ('rally', '1'),\n",
       "   ('Savannah', '1'),\n",
       "   ('speaker', '1')]),\n",
       " ('In the Blue_Ridge meeting the audience was warned that entering a candidate for governor would force it to take petitions out into voting_precincts to obtain the signatures of registered voters ',\n",
       "  [('meeting', '1'),\n",
       "   ('audience', '1'),\n",
       "   ('candidate', '1'),\n",
       "   ('governor', '1'),\n",
       "   ('petitions', '1'),\n",
       "   ('signatures', '1')]),\n",
       " ('Despite the warning there was a unanimous vote to enter a candidate according_to Republicans who attended ',\n",
       "  [('warning', '2'), ('vote', '1'), ('candidate', '1'), ('Republicans', '1')]),\n",
       " ('When the crowd was asked whether it wanted to wait one more term to make the race it voted no and there were no dissents ',\n",
       "  [('crowd', '1'), ('term', '2'), ('race', '1'), ('dissents', '2')]),\n",
       " ('The largest hurdle the Republicans would have to face is a state law which says that before making a first race one of two alternative courses must be taken ',\n",
       "  [('hurdle', '1'),\n",
       "   ('Republicans', '1'),\n",
       "   ('state', '4'),\n",
       "   ('law', '2'),\n",
       "   ('race', '1'),\n",
       "   ('courses', '3')]),\n",
       " ('Five per_cent of the voters in each county must sign petitions requesting that the Republicans be allowed to place names of candidates on the general_election ballot or The Republicans must hold a primary under the county unit system a system which the party opposes in its platform ',\n",
       "  [('county', '1'),\n",
       "   ('petitions', '1'),\n",
       "   ('Republicans', '1'),\n",
       "   ('names', '1'),\n",
       "   ('candidates', '1'),\n",
       "   ('ballot', '2'),\n",
       "   ('Republicans', '1'),\n",
       "   ('primary', '1'),\n",
       "   ('county', '1'),\n",
       "   ('unit', '3'),\n",
       "   ('system', '4'),\n",
       "   ('system', '4'),\n",
       "   ('party', '1'),\n",
       "   ('platform', '2')]),\n",
       " (\"Sam_Caldwell State_Highway_Department public_relations director resigned Tuesday to work for Lt._Gov._Garland_Byrd 's campaign \",\n",
       "  [('director', '1'), ('campaign', '1')]),\n",
       " (\"Caldwell 's resignation had been expected for some time \",\n",
       "  [('resignation', '3'), ('time', '3')]),\n",
       " ('He will be succeeded by Rob_Ledford of Gainesville who has been an assistant more than three years ',\n",
       "  [('assistant', '1'), ('years', '1')]),\n",
       " ('When the gubernatorial campaign starts Caldwell is expected to become a campaign coordinator for Byrd ',\n",
       "  [('campaign', '1'), ('campaign', '1')]),\n",
       " ('The Georgia_Legislature will wind_up its 1961 session Monday and head for home where some of the highway bond money it approved will follow shortly ',\n",
       "  [('session', '2'), ('bond', '2'), ('money', '1')]),\n",
       " ('Before adjournment Monday afternoon the Senate is expected to approve a study of the number of legislators allotted to rural and urban_areas to determine what adjustments should be made ',\n",
       "  [('adjournment', '1'),\n",
       "   ('afternoon', '1'),\n",
       "   ('Senate', '1'),\n",
       "   ('study', '1'),\n",
       "   ('number', '2'),\n",
       "   ('rural', '1'),\n",
       "   ('adjustments', '1')]),\n",
       " ('Gov._Vandiver is expected to make the traditional visit to both chambers as they work toward adjournment ',\n",
       "  [('visit', '1'), ('chambers', '3'), ('adjournment', '1')]),\n",
       " ('Vandiver likely will mention the 100 million highway bond issue approved earlier in the session as his first priority item ',\n",
       "  [('million', '1'),\n",
       "   ('bond', '2'),\n",
       "   ('issue', '1'),\n",
       "   ('session', '2'),\n",
       "   ('priority', '1'),\n",
       "   ('item', '4')]),\n",
       " ('Meanwhile it was learned the State_Highway_Department is very near being ready to issue the first 30 million worth of highway reconstruction bonds ',\n",
       "  [('worth', '1'), ('reconstruction', '2'), ('bonds', '2')]),\n",
       " (\"The bond issue will go to the state courts for a friendly test_suit to test the validity of the act and_then the sales will begin and contracts let for repair work on some of Georgia 's most heavily traveled highways \",\n",
       "  [('bond', '2'),\n",
       "   ('issue', '1'),\n",
       "   ('state', '4'),\n",
       "   ('courts', '1'),\n",
       "   ('validity', '2'),\n",
       "   ('act', '1'),\n",
       "   ('sales', '1'),\n",
       "   ('contracts', '2'),\n",
       "   ('repair', '1'),\n",
       "   ('work', '1'),\n",
       "   ('Georgia', '1')]),\n",
       " ('A Highway_Department source said there also is a plan there to issue some 3 million to 4 million worth of Rural_Roads_Authority bonds for rural road construction work ',\n",
       "  [('source', '5'),\n",
       "   ('plan', '1'),\n",
       "   ('million', '1'),\n",
       "   ('million', '1'),\n",
       "   ('worth', '2'),\n",
       "   ('bonds', '2'),\n",
       "   ('road', '1'),\n",
       "   ('construction', '1'),\n",
       "   ('work', '1')]),\n",
       " ('The department apparently intends to make the Rural_Roads_Authority a revolving_fund under which new bonds would be issued every time a portion of the old ones are paid_off by tax authorities ',\n",
       "  [('department', '1'),\n",
       "   ('bonds', '2'),\n",
       "   ('time', '1'),\n",
       "   ('portion', '3'),\n",
       "   ('tax', '1'),\n",
       "   ('authorities', '1')]),\n",
       " ('Vandiver opened his race for governor in 1958 with a battle in the Legislature against the issuance of 50 million worth of additional rural roads bonds proposed by then Gov._Marvin_Griffin ',\n",
       "  [('race', '1'),\n",
       "   ('governor', '1'),\n",
       "   ('battle', '2'),\n",
       "   ('million', '1'),\n",
       "   ('worth', '1'),\n",
       "   ('roads', '1'),\n",
       "   ('bonds', '2')]),\n",
       " ('The Highway_Department source told The_Constitution however that Vandiver has not been consulted yet about the plans to issue the new rural roads bonds ',\n",
       "  [('source', '5'), ('plans', '1'), ('roads', '1'), ('bonds', '2')]),\n",
       " (\"Schley_County_Rep._B._D._Pelham will offer a resolution Monday in the House to rescind the body 's action of Friday in voting itself a 10 per day increase in expense allowances \",\n",
       "  [('resolution', '1'),\n",
       "   ('body', '2'),\n",
       "   ('action', '1'),\n",
       "   ('voting', '1'),\n",
       "   ('day', '1'),\n",
       "   ('increase', '2'),\n",
       "   ('expense', '1'),\n",
       "   ('allowances', '2')]),\n",
       " ('Pelham said Sunday night there was research being done on whether the quickie vote on the increase can be repealed outright or whether notice would have to first be given that reconsideration of the action would be sought ',\n",
       "  [('Sunday', '1'),\n",
       "   ('night', '1'),\n",
       "   ('research', '1'),\n",
       "   ('vote', '1'),\n",
       "   ('increase', '2'),\n",
       "   ('notice', '3'),\n",
       "   ('reconsideration', '1'),\n",
       "   ('action', '1')]),\n",
       " ('While emphasizing that technical details were not fully worked_out Pelham said his resolution would seek to set_aside the privilege resolution which the House voted through 87 31 ',\n",
       "  [('details', '1'),\n",
       "   ('resolution', '1'),\n",
       "   ('privilege', '2'),\n",
       "   ('resolution', '1')]),\n",
       " ('A similar resolution passed in the Senate by a vote of 29 5 ',\n",
       "  [('resolution', '1'),\n",
       "   ('Senate', '1'),\n",
       "   ('vote', '1'),\n",
       "   ('29', '1'),\n",
       "   ('5', '1')]),\n",
       " ('As of Sunday night there was no word of a resolution being offered there to rescind the action ',\n",
       "  [('Sunday', '1'),\n",
       "   ('night', '1'),\n",
       "   ('word', '2'),\n",
       "   ('resolution', '1'),\n",
       "   ('action', '1')]),\n",
       " ('Pelham pointed_out that Georgia voters last November rejected a constitutional amendment to allow legislators to vote on pay raises for future Legislature sessions ',\n",
       "  [('Georgia', '1'),\n",
       "   ('amendment', '1'),\n",
       "   ('vote', '1'),\n",
       "   ('pay', '1'),\n",
       "   ('raises', '1'),\n",
       "   ('sessions', '2')]),\n",
       " ('A veteran Jackson_County legislator will ask the Georgia_House Monday to back federal aid to education something it has consistently opposed in the past ',\n",
       "  [('aid', '3'), ('education', '4'), ('past', '1')]),\n",
       " ('Rep._Mac_Barber of Commerce is asking the House in a privilege resolution to endorse increased federal support for public education provided_that such funds be received and expended as state funds ',\n",
       "  [('privilege', '1'),\n",
       "   ('resolution', '1'),\n",
       "   ('support', '1'),\n",
       "   ('education', '4'),\n",
       "   ('funds', '1'),\n",
       "   ('state', '4'),\n",
       "   ('funds', '1')]),\n",
       " ('Barber who is in his 13th year as a legislator said there are some members of our congressional delegation in Washington who would_like to see it the resolution passed ',\n",
       "  [('year', '1'),\n",
       "   ('members', '1'),\n",
       "   ('delegation', '1'),\n",
       "   ('Washington', '3'),\n",
       "   ('resolution', '1')]),\n",
       " (\"But he added that none of Georgia 's congressmen specifically asked him to offer the resolution \",\n",
       "  [('Georgia', '1'), ('resolution', '1')]),\n",
       " ('The resolution which Barber tossed into the House hopper Friday will be formally read Monday ',\n",
       "  [('resolution', '1'), ('hopper', '1')]),\n",
       " ('It says that in the event Congress does provide this increase in federal funds the State_Board_of_Education should be directed to give priority to teacher pay raises ',\n",
       "  [('event', '2'),\n",
       "   ('increase', '2'),\n",
       "   ('funds', '1'),\n",
       "   ('priority', '1'),\n",
       "   ('teacher', '1'),\n",
       "   ('pay', '1'),\n",
       "   ('raises', '1')]),\n",
       " ('After a long hot controversy Miller_County has a new school_superintendent elected as a policeman put it in the coolest election I ever saw in_this county ',\n",
       "  [('election', '1'), ('county', '1')]),\n",
       " ('The new school_superintendent is Harry_Davis a veteran agriculture teacher who defeated Felix_Bush a school_principal and chairman of the Miller_County_Democratic_Executive_Committee ',\n",
       "  [('agriculture', '1'), ('teacher', '1'), ('chairman', '1')]),\n",
       " (\"Davis received 1119 votes in Saturday 's election and Bush got 402 \",\n",
       "  [('votes', '2'), ('election', '1')]),\n",
       " ('Ordinary Carey_Williams armed with a pistol stood_by at the polls to insure order ',\n",
       "  [('Ordinary', '1'), ('polls', '1'), ('order', '3')]),\n",
       " ('This was the coolest calmest election I ever saw Colquitt_Policeman_Tom_Williams said ',\n",
       "  [('election', '1')]),\n",
       " ('Being at the polls was just like being at church ',\n",
       "  [('polls', '1'), ('church', '3')]),\n",
       " (\"I did n't smell a drop of liquor and we did n't have a_bit of trouble \",\n",
       "  [('drop', '2'), ('liquor', '1'), ('trouble', '2')]),\n",
       " ('The campaign leading to the election was not so quiet however ',\n",
       "  [('campaign', '1'), ('election', '1')]),\n",
       " ('It was marked by controversy anonymous midnight phone_calls and veiled threats of violence ',\n",
       "  [('threats', '3'), ('violence', '1')]),\n",
       " ('The former county school_superintendent George_P._Callan shot himself to death March 18 four days after he resigned his post in a dispute with the county school_board ',\n",
       "  [('county', '1'),\n",
       "   ('death', '3'),\n",
       "   ('March', '1'),\n",
       "   ('days', '1'),\n",
       "   ('post', '3'),\n",
       "   ('dispute', '1'),\n",
       "   ('county', '1')]),\n",
       " ('During the election campaign both candidates Davis and Bush reportedly received anonymous telephone_calls ',\n",
       "  [('election', '1'), ('campaign', '1'), ('candidates', '1')]),\n",
       " ('Ordinary Williams said he too was subjected to anonymous calls soon after he scheduled the election ',\n",
       "  [('Ordinary', '1'), ('calls', '1'), ('election', '1')]),\n",
       " ('Many local citizens feared that there would be irregularities at the polls and Williams got himself a permit to carry a gun and promised an orderly election ',\n",
       "  [('irregularities', '1'),\n",
       "   ('polls', '1'),\n",
       "   ('permit', '1'),\n",
       "   ('gun', '1'),\n",
       "   ('election', '1')]),\n",
       " ('Sheriff_Felix_Tabb said the ordinary apparently made_good his promise ',\n",
       "  [('ordinary', '1'), ('promise', '1')]),\n",
       " ('Everything went real smooth the sheriff said ', []),\n",
       " (\"There was n't a_bit of trouble \", [('trouble', '2')])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_xml(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lesk(word, sentence):\n",
    "    '''\n",
    "    Lesk algorithm implementation. Given a word and a sentence in which it appears,\n",
    "    it returns the best sense of the word.\n",
    "    Args:\n",
    "        word: word to disambiguate\n",
    "        sentence: sentence in wich the word occour\n",
    "    Returns:\n",
    "        best sense of word\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "\n",
    "def lesk(word, sentence):\n",
    "    \"\"\"Lesk algorithm implementation. Given a word and a sentence in which it appears,\n",
    "    it returns the best sense of the word.\n",
    "    Args:\n",
    "        word: word to disambiguate\n",
    "        sentence: sentence to compare\n",
    "    Returns:\n",
    "        best sense of word\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculating the synset of the given word inside WN\n",
    "    word_senses = wn.synsets(word)\n",
    "    best_sense = word_senses[0]\n",
    "    max_overlap = 0\n",
    "\n",
    "    # I choose the bag of words approach\n",
    "    context = bag_of_word(sentence)\n",
    "\n",
    "    for sense in word_senses:\n",
    "        # set of words in the gloss\n",
    "        signature = bag_of_word(sense.definition())\n",
    "\n",
    "        # and examples of the given sense\n",
    "        examples = sense.examples()\n",
    "        for ex in examples:\n",
    "            # after this line, signature will contain for all the words, their\n",
    "            # bag of words definition and their examples\n",
    "            signature = signature.union(bag_of_word(ex))\n",
    "\n",
    "        overlap = compute_overlap(signature, context)\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            best_sense = sense\n",
    "\n",
    "    return best_sense\n",
    "\n",
    "\n",
    "def bag_of_word(sent):\n",
    "    \"\"\"Auxiliary function for the Lesk algorithm. Transforms the given sentence\n",
    "    according to the bag of words approach, apply lemmatization, stop words\n",
    "    and punctuation removal.\n",
    "    Args:\n",
    "        sent: sentence\n",
    "    Returns:\n",
    "        bag of words\n",
    "    \"\"\"\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    punctuation = {',', ';', '(', ')', '{', '}', ':', '?', '!'}\n",
    "    # Returns the input word unchanged if it cannot be found in WordNet.\n",
    "    wnl = nltk.WordNetLemmatizer()\n",
    "    # Return a tokenized copy of text, using NLTKâs recommended word tokenizer (Treebank + PunkSentence)\n",
    "    tokens = nltk.word_tokenize(sent)\n",
    "    tokens = list(filter(lambda x: x not in stop_words and x not in punctuation, tokens))\n",
    "    return set(wnl.lemmatize(t) for t in tokens)\n",
    "\n",
    "\n",
    "def compute_overlap(signature, context):\n",
    "    \"\"\"Auxiliary function for the Lesk algorithm. Computes the number of words in\n",
    "    common between signature and context.\n",
    "    Args: \n",
    "        signature: bag of words of the signature (e.g. definitions + examples)\n",
    "        context: bag of words of the context (e.g. sentence)\n",
    "    Returns:\n",
    "        number of elements in commons\n",
    "    \"\"\"\n",
    "\n",
    "    return len(signature & context)\n",
    "\n",
    "\n",
    "def get_sense_index(word, sense):\n",
    "    \"\"\"Given a ambiguous word and a sense of that word, it returns the\n",
    "    corresponding index of the sense in the synsets list associated with the\n",
    "    word indices starts with 1.\n",
    "    Args: \n",
    "        word: ambiguous word (with more that 1 sense)\n",
    "        sense: sense of the word\n",
    "    Returns:\n",
    "        index of the sense in the synsets list of the word\n",
    "    \"\"\"\n",
    "\n",
    "    senses = wn.synsets(word)\n",
    "    return senses.index(sense) + 1\n",
    "\n",
    "\n",
    "def pos_validity(pos, text, word):\n",
    "    \"\"\"Auxiliary function for the parse_xml\n",
    "    Args:\n",
    "        pos:\n",
    "        text:\n",
    "        word: ambiguous word (with more that 1 sense)\n",
    "    Returns:\n",
    "        boolean: True if the word is valid and false otherwise\n",
    "    \"\"\"\n",
    "    return pos == 'NN' and '_' not in text and len(wn.synsets(text)) > 1 and 'wnsn' in word.attrib\n",
    "\n",
    "\n",
    "def max_freq(word):\n",
    "    \"\"\"\n",
    "    Helper method for lesk_demaria\n",
    "    :param word of interest\n",
    "    :return: frequency of the word\n",
    "    \"\"\"\n",
    "    synsets = wn.synsets(word)\n",
    "    sense2freq = None\n",
    "    freq_max = 0\n",
    "\n",
    "    for s in synsets:\n",
    "        freq = 0\n",
    "        for lemma in s.lemmas():\n",
    "            freq += lemma.count()\n",
    "            if freq > freq_max:\n",
    "                freq_max = freq\n",
    "                sense2freq = s\n",
    "    return sense2freq\n",
    "\n",
    "\n",
    "def lesk_demaria(word, sentence):\n",
    "    \"\"\"\n",
    "    Given a word and a sentence in which it appears, it returns the best sense of the word.\n",
    "    DeMaria Implementation more precise than simpler lesk above thanks to max_freq\n",
    "    Args:\n",
    "        word: word to disambiguate\n",
    "        sentence: sentence to compare\n",
    "    Returns:\n",
    "        best sense of word\n",
    "    \"\"\"\n",
    "    # inizializzazione\n",
    "    max_overlap = 0\n",
    "    best_sense = max_freq(word)\n",
    "\n",
    "    # If I choose the bag of words approach\n",
    "    context = bag_of_word(sentence)\n",
    "    signature = []\n",
    "\n",
    "    for ss in wn.synsets(word):\n",
    "        signature += ss.definition().split()\n",
    "        signature += ss.lemma_names()\n",
    "\n",
    "        overlap = set(signature).intersection(context)\n",
    "        signature.clear()\n",
    "\n",
    "        if len(overlap) > max_overlap:\n",
    "            best_sense = ss\n",
    "            max_overlap = len(overlap)\n",
    "\n",
    "    return best_sense"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venvradicioni': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe30bb084dadcc2974aabac99d8c6a813637b467837e0e94701709de5a097010"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
