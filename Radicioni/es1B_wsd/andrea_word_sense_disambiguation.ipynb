{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://web.eecs.umich.edu/~mihalcea/downloads.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import semcor\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "import random\n",
    "import string\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzioni usate dall'algoritmo di Lesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(sentence):\n",
    "    # bag of words approach\n",
    "    sentence.lower()\n",
    "    tokens = word_tokenize(sentence) \n",
    "    tokens = list(filter(lambda token: token not in string.punctuation, tokens))\n",
    "    wnl = nltk.WordNetLemmatizer()\n",
    "    ps = PorterStemmer()\n",
    "    return [ps.stem(wnl.lemmatize(token.lower())) for token in tokens if token not in stopwords.words('english')] #lemma o stemma? solo uno dei due da lasciare\n",
    "\n",
    "def get_gloss_examples(sense):\n",
    "    gloss = get_context(sense.definition())\n",
    "    examples = get_context(' '.join((sense).examples()))\n",
    "    return gloss + examples\n",
    "\n",
    "def get_overlap(list_1, list_2):\n",
    "    return [value for value in list_1 if value in list_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo di Lesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lesk(word, sentence):\n",
    "    best_sense = wn.synsets(word)[0]\n",
    "    max_overlap = 0\n",
    "    context = get_context(sentence)\n",
    "    sifnature = None\n",
    "    overlap = None\n",
    "    for sense in wn.synsets(word):\n",
    "        signature = get_gloss_examples(sense)\n",
    "        overlap = get_overlap(context, signature)\n",
    "        if len(overlap) > max_overlap:\n",
    "            max_overlap = len(overlap)\n",
    "            best_sense = sense\n",
    "    return best_sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzioni utili per l'esecuzione dell'algoritmo di Lesk su 50 frasi scelte randomicamente da SemCor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nouns(list_of_sentences):\n",
    "    nouns = []\n",
    "    ps = PorterStemmer()\n",
    "    wnl = WordNetLemmatizer()\n",
    "    for sentence in list_of_sentences:\n",
    "        for word in sentence:\n",
    "            print(f'{word[0]}\\n\\n\\n')\n",
    "            if 'NN' in str(word) and len(word) == 1 and word[0]: \n",
    "            #prendo solo parole singole per evitare i noun phrase e che inizino con la minuscola cos√¨ evito i nomi propri.\n",
    "                nouns.append(word)\n",
    "                break\n",
    "    return nouns\n",
    "\n",
    "def get_rand_elems(array):\n",
    "    rands = random.sample(range(0, len(array)), 50)\n",
    "    return [array[i] for i in rands]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['they took a cable car to the top of the mountain']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'a set that is closed, associative, has an identity element and every element has an inverse'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"we went up to the mountains by car\"\n",
    "print(wn.synsets('car')[4].examples())\n",
    "lesk('car', sentence)\n",
    "wn.synsets('group')[2].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sentences = semcor.tagged_sents(tag=\"both\")\n",
    "random_sentences = get_rand_elems(tagged_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select a NN from every of the 50 sentences randomly selected from semcor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "\n",
      "\n",
      "\n",
      "(NN phenomenon)\n",
      "\n",
      "\n",
      "\n",
      "Player\n",
      "\n",
      "\n",
      "\n",
      "(VB Is)\n",
      "\n",
      "\n",
      "\n",
      "it\n",
      "\n",
      "\n",
      "\n",
      "(RB not)\n",
      "\n",
      "\n",
      "\n",
      "(JJ ironical)\n",
      "\n",
      "\n",
      "\n",
      "that\n",
      "\n",
      "\n",
      "\n",
      "(NE (NNP Roger Williams))\n",
      "\n",
      "\n",
      "\n",
      "The\n",
      "\n",
      "\n",
      "\n",
      "FBI\n",
      "\n",
      "\n",
      "\n",
      "Yet\n",
      "\n",
      "\n",
      "\n",
      "the\n",
      "\n",
      "\n",
      "\n",
      "press\n",
      "\n",
      "\n",
      "\n",
      "That\n",
      "\n",
      "\n",
      "\n",
      "(VB was)\n",
      "\n",
      "\n",
      "\n",
      "(NE (NNP Bartoli))\n",
      "\n",
      "\n",
      "\n",
      "This\n",
      "\n",
      "\n",
      "\n",
      "may\n",
      "\n",
      "\n",
      "\n",
      "(VB be)\n",
      "\n",
      "\n",
      "\n",
      "(JJ helpful)\n",
      "\n",
      "\n",
      "\n",
      "in\n",
      "\n",
      "\n",
      "\n",
      "(VB improving)\n",
      "\n",
      "\n",
      "\n",
      "the\n",
      "\n",
      "\n",
      "\n",
      "(JJ competitive)\n",
      "\n",
      "\n",
      "\n",
      "(NN position)\n",
      "\n",
      "\n",
      "\n",
      "After\n",
      "\n",
      "\n",
      "\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "we\n",
      "\n",
      "\n",
      "\n",
      "(VB began)\n",
      "\n",
      "\n",
      "\n",
      "to\n",
      "\n",
      "\n",
      "\n",
      "(VB get)\n",
      "\n",
      "\n",
      "\n",
      "``\n",
      "\n",
      "\n",
      "\n",
      "visitors\n",
      "\n",
      "\n",
      "\n",
      "If\n",
      "\n",
      "\n",
      "\n",
      "you\n",
      "\n",
      "\n",
      "\n",
      "(VB use)\n",
      "\n",
      "\n",
      "\n",
      "(NN parking)\n",
      "\n",
      "\n",
      "\n",
      "I\n",
      "\n",
      "\n",
      "\n",
      "(VB was)\n",
      "\n",
      "\n",
      "\n",
      "suddenly\n",
      "\n",
      "\n",
      "\n",
      "conscious\n",
      "\n",
      "\n",
      "\n",
      "of\n",
      "\n",
      "\n",
      "\n",
      "my\n",
      "\n",
      "\n",
      "\n",
      "bare\n",
      "\n",
      "\n",
      "\n",
      "arms\n",
      "\n",
      "\n",
      "\n",
      "They\n",
      "\n",
      "\n",
      "\n",
      "(JJ all)\n",
      "\n",
      "\n",
      "\n",
      "(VB prayed)\n",
      "\n",
      "\n",
      "\n",
      "(RB now)\n",
      "\n",
      "\n",
      "\n",
      "that\n",
      "\n",
      "\n",
      "\n",
      "the\n",
      "\n",
      "\n",
      "\n",
      "(NN North)\n",
      "\n",
      "\n",
      "\n",
      "If\n",
      "\n",
      "\n",
      "\n",
      "(NE (NNP Nikita))\n",
      "\n",
      "\n",
      "\n",
      "(NE (NNP Hans))\n",
      "\n",
      "\n",
      "\n",
      "Board\n",
      "\n",
      "\n",
      "\n",
      "(VB indicated)\n",
      "\n",
      "\n",
      "\n",
      "Monday\n",
      "\n",
      "\n",
      "\n",
      "``\n",
      "\n",
      "\n",
      "\n",
      "A\n",
      "\n",
      "\n",
      "\n",
      "child\n",
      "\n",
      "\n",
      "\n",
      "We\n",
      "\n",
      "\n",
      "\n",
      "(VB like)\n",
      "\n",
      "\n",
      "\n",
      "to\n",
      "\n",
      "\n",
      "\n",
      "(VB run)\n",
      "\n",
      "\n",
      "\n",
      "a\n",
      "\n",
      "\n",
      "\n",
      "nice\n",
      "\n",
      "\n",
      "\n",
      "quiet\n",
      "\n",
      "\n",
      "\n",
      "place\n",
      "\n",
      "\n",
      "\n",
      "I\n",
      "\n",
      "\n",
      "\n",
      "(VB looked for)\n",
      "\n",
      "\n",
      "\n",
      "(NE (NNP Jessica))\n",
      "\n",
      "\n",
      "\n",
      "There\n",
      "\n",
      "\n",
      "\n",
      "is\n",
      "\n",
      "\n",
      "\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "to\n",
      "\n",
      "\n",
      "\n",
      "(VB begin)\n",
      "\n",
      "\n",
      "\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "an\n",
      "\n",
      "\n",
      "\n",
      "(JJ important)\n",
      "\n",
      "\n",
      "\n",
      "(NN sex)\n",
      "\n",
      "\n",
      "\n",
      "The\n",
      "\n",
      "\n",
      "\n",
      "concept\n",
      "\n",
      "\n",
      "\n",
      "Though\n",
      "\n",
      "\n",
      "\n",
      "they\n",
      "\n",
      "\n",
      "\n",
      "would\n",
      "\n",
      "\n",
      "\n",
      "(VB produce)\n",
      "\n",
      "\n",
      "\n",
      "(JJ some)\n",
      "\n",
      "\n",
      "\n",
      "(RB very)\n",
      "\n",
      "\n",
      "\n",
      "(JJ memorable)\n",
      "\n",
      "\n",
      "\n",
      "and\n",
      "\n",
      "\n",
      "\n",
      "(JJ lasting)\n",
      "\n",
      "\n",
      "\n",
      "(NN songs)\n",
      "\n",
      "\n",
      "\n",
      "This\n",
      "\n",
      "\n",
      "\n",
      "(VB means)\n",
      "\n",
      "\n",
      "\n",
      "that\n",
      "\n",
      "\n",
      "\n",
      "a\n",
      "\n",
      "\n",
      "\n",
      "(JJ great)\n",
      "\n",
      "\n",
      "\n",
      "(JJ many)\n",
      "\n",
      "\n",
      "\n",
      "(RB academically)\n",
      "\n",
      "\n",
      "\n",
      "(JJ talented)\n",
      "\n",
      "\n",
      "\n",
      "(NN girls)\n",
      "\n",
      "\n",
      "\n",
      "Below\n",
      "\n",
      "\n",
      "\n",
      "decks\n",
      "\n",
      "\n",
      "\n",
      "Mrs.\n",
      "\n",
      "\n",
      "\n",
      "(VB compared)\n",
      "\n",
      "\n",
      "\n",
      "her\n",
      "\n",
      "\n",
      "\n",
      "feelings\n",
      "\n",
      "\n",
      "\n",
      "The\n",
      "\n",
      "\n",
      "\n",
      "(JJ morning)\n",
      "\n",
      "\n",
      "\n",
      "(NN hawk)\n",
      "\n",
      "\n",
      "\n",
      "On\n",
      "\n",
      "\n",
      "\n",
      "this\n",
      "\n",
      "\n",
      "\n",
      "point\n",
      "\n",
      "\n",
      "\n",
      "(RB Instead)\n",
      "\n",
      "\n",
      "\n",
      "of\n",
      "\n",
      "\n",
      "\n",
      "the\n",
      "\n",
      "\n",
      "\n",
      "(NN observer)\n",
      "\n",
      "\n",
      "\n",
      "The\n",
      "\n",
      "\n",
      "\n",
      "(JJ artistic)\n",
      "\n",
      "\n",
      "\n",
      "(NN interest)\n",
      "\n",
      "\n",
      "\n",
      "New\n",
      "\n",
      "\n",
      "\n",
      "(VB figures)\n",
      "\n",
      "\n",
      "\n",
      "its\n",
      "\n",
      "\n",
      "\n",
      "peak\n",
      "\n",
      "\n",
      "\n",
      "``\n",
      "\n",
      "\n",
      "\n",
      "(JJ Damned)\n",
      "\n",
      "\n",
      "\n",
      "if\n",
      "\n",
      "\n",
      "\n",
      "I\n",
      "\n",
      "\n",
      "\n",
      "will\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "One\n",
      "\n",
      "\n",
      "\n",
      "high-up\n",
      "\n",
      "\n",
      "\n",
      "camera\n",
      "\n",
      "\n",
      "\n",
      "(NE (NNP Thornburg))\n",
      "\n",
      "\n",
      "\n",
      "He\n",
      "\n",
      "\n",
      "\n",
      "(VB is)\n",
      "\n",
      "\n",
      "\n",
      "(RB not)\n",
      "\n",
      "\n",
      "\n",
      "(JJ lost)\n",
      "\n",
      "\n",
      "\n",
      "in\n",
      "\n",
      "\n",
      "\n",
      "the\n",
      "\n",
      "\n",
      "\n",
      "(NN abyss)\n",
      "\n",
      "\n",
      "\n",
      "It\n",
      "\n",
      "\n",
      "\n",
      "(VB is)\n",
      "\n",
      "\n",
      "\n",
      "their\n",
      "\n",
      "\n",
      "\n",
      "job\n",
      "\n",
      "\n",
      "\n",
      "They\n",
      "\n",
      "\n",
      "\n",
      "had\n",
      "\n",
      "\n",
      "\n",
      "the\n",
      "\n",
      "\n",
      "\n",
      "(NN house)\n",
      "\n",
      "\n",
      "\n",
      "This\n",
      "\n",
      "\n",
      "\n",
      "must\n",
      "\n",
      "\n",
      "\n",
      "(VB be due)\n",
      "\n",
      "\n",
      "\n",
      "to\n",
      "\n",
      "\n",
      "\n",
      "a\n",
      "\n",
      "\n",
      "\n",
      "(RB completely)\n",
      "\n",
      "\n",
      "\n",
      "(JJ identical)\n",
      "\n",
      "\n",
      "\n",
      "(NN response)\n",
      "\n",
      "\n",
      "\n",
      "(NE (NNP Spahn))\n",
      "\n",
      "\n",
      "\n",
      "Could\n",
      "\n",
      "\n",
      "\n",
      "your\n",
      "\n",
      "\n",
      "\n",
      "(NN future)\n",
      "\n",
      "\n",
      "\n",
      "The\n",
      "\n",
      "\n",
      "\n",
      "(NN kiss)\n",
      "\n",
      "\n",
      "\n",
      "Thanks\n",
      "\n",
      "\n",
      "\n",
      "Are\n",
      "\n",
      "\n",
      "\n",
      "there\n",
      "\n",
      "\n",
      "\n",
      "(NN possibilities)\n",
      "\n",
      "\n",
      "\n",
      "He\n",
      "\n",
      "\n",
      "\n",
      "did\n",
      "\n",
      "\n",
      "\n",
      "(RB not)\n",
      "\n",
      "\n",
      "\n",
      "want\n",
      "\n",
      "\n",
      "\n",
      "(VB bring)\n",
      "\n",
      "\n",
      "\n",
      "the\n",
      "\n",
      "\n",
      "\n",
      "(NE (NNP Andruses))\n",
      "\n",
      "\n",
      "\n",
      "(RB Still)\n",
      "\n",
      "\n",
      "\n",
      "I\n",
      "\n",
      "\n",
      "\n",
      "did\n",
      "\n",
      "\n",
      "\n",
      "(RB n't)\n",
      "\n",
      "\n",
      "\n",
      "(VB think)\n",
      "\n",
      "\n",
      "\n",
      "she\n",
      "\n",
      "\n",
      "\n",
      "was\n",
      "\n",
      "\n",
      "\n",
      "(VB twotiming)\n",
      "\n",
      "\n",
      "\n",
      "me\n",
      "\n",
      "\n",
      "\n",
      "with\n",
      "\n",
      "\n",
      "\n",
      "(NE (NNP Precious))\n",
      "\n",
      "\n",
      "\n",
      "The\n",
      "\n",
      "\n",
      "\n",
      "air\n",
      "\n",
      "\n",
      "\n",
      "Why\n",
      "\n",
      "\n",
      "\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "I\n",
      "\n",
      "\n",
      "\n",
      "(RB once)\n",
      "\n",
      "\n",
      "\n",
      "(VB used)\n",
      "\n",
      "\n",
      "\n",
      "this\n",
      "\n",
      "\n",
      "\n",
      "(NN machine)\n",
      "\n",
      "\n",
      "\n",
      "``\n",
      "\n",
      "\n",
      "\n",
      "Oh\n",
      "\n",
      "\n",
      "\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "I'm\n",
      "\n",
      "\n",
      "\n",
      "(RB so)\n",
      "\n",
      "\n",
      "\n",
      "(VB delighted)\n",
      "\n",
      "\n",
      "\n",
      "to\n",
      "\n",
      "\n",
      "\n",
      "(VB meet)\n",
      "\n",
      "\n",
      "\n",
      "you\n",
      "\n",
      "\n",
      "\n",
      "''\n",
      "\n",
      "\n",
      "\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "she\n",
      "\n",
      "\n",
      "\n",
      "(VB gushed)\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "We\n",
      "\n",
      "\n",
      "\n",
      "(VB assume)\n",
      "\n",
      "\n",
      "\n",
      "that\n",
      "\n",
      "\n",
      "\n",
      "(JJ average)\n",
      "\n",
      "\n",
      "\n",
      "(JJ total)\n",
      "\n",
      "\n",
      "\n",
      "(NN unit cost)\n",
      "\n",
      "\n",
      "\n",
      "A\n",
      "\n",
      "\n",
      "\n",
      "(JJ non)\n",
      "\n",
      "\n",
      "\n",
      "(JJ contributory)\n",
      "\n",
      "\n",
      "\n",
      "(NN plan)\n",
      "\n",
      "\n",
      "\n",
      "He\n",
      "\n",
      "\n",
      "\n",
      "(VB felt)\n",
      "\n",
      "\n",
      "\n",
      "a\n",
      "\n",
      "\n",
      "\n",
      "(JJ puppyish)\n",
      "\n",
      "\n",
      "\n",
      "(NN need)\n",
      "\n",
      "\n",
      "\n",
      "Addition\n",
      "\n",
      "\n",
      "\n",
      "While\n",
      "\n",
      "\n",
      "\n",
      "(VB working out)\n",
      "\n",
      "\n",
      "\n",
      "in\n",
      "\n",
      "\n",
      "\n",
      "(NE (NNP Sylvania))\n",
      "\n",
      "\n",
      "\n",
      "[Tree(Lemma('phenomenon.n.01.phenomenon'), [Tree('NN', ['phenomenon'])]),\n",
      " Tree('NNP', ['Player']),\n",
      " Tree(Lemma('person.n.01.person'), [Tree('NE', [Tree('NNP', ['Roger', 'Williams'])])]),\n",
      " Tree('NNP', ['FBI']),\n",
      " Tree('NN', ['press']),\n",
      " Tree(Lemma('person.n.01.person'), [Tree('NE', [Tree('NNP', ['Bartoli'])])]),\n",
      " Tree(Lemma('status.n.01.position'), [Tree('NN', ['position'])]),\n",
      " Tree('NNS', ['visitors']),\n",
      " Tree(Lemma('parking.n.01.parking'), [Tree('NN', ['parking'])]),\n",
      " Tree('NNS', ['arms']),\n",
      " Tree(Lemma('union.n.02.North'), [Tree('NN', ['North'])]),\n",
      " Tree(Lemma('person.n.01.person'), [Tree('NE', [Tree('NNP', ['Nikita'])])]),\n",
      " Tree(Lemma('person.n.01.person'), [Tree('NE', [Tree('NNP', ['Hans'])])]),\n",
      " Tree('NNP', ['Monday']),\n",
      " Tree('NN', ['child']),\n",
      " Tree('NN', ['place']),\n",
      " Tree(Lemma('person.n.01.person'), [Tree('NE', [Tree('NNP', ['Jessica'])])]),\n",
      " Tree(Lemma('sex.n.02.sex'), [Tree('NN', ['sex'])]),\n",
      " Tree('NN', ['concept']),\n",
      " Tree(Lemma('song.n.01.song'), [Tree('NN', ['songs'])]),\n",
      " Tree(Lemma('girl.n.01.girl'), [Tree('NN', ['girls'])]),\n",
      " Tree('NNS', ['decks']),\n",
      " Tree('NNS', ['feelings']),\n",
      " Tree(Lemma('hawk.n.01.hawk'), [Tree('NN', ['hawk'])]),\n",
      " Tree('NN', ['point']),\n",
      " Tree(Lemma('perceiver.n.01.observer'), [Tree('NN', ['observer'])]),\n",
      " Tree(Lemma('interest.n.01.interest'), [Tree('NN', ['interest'])]),\n",
      " Tree('NN', ['peak']),\n",
      " Tree('NN', ['camera']),\n",
      " Tree(Lemma('person.n.01.person'), [Tree('NE', [Tree('NNP', ['Thornburg'])])]),\n",
      " Tree(Lemma('abyss.n.01.abyss'), [Tree('NN', ['abyss'])]),\n",
      " Tree('NN', ['job']),\n",
      " Tree(Lemma('house.n.01.house'), [Tree('NN', ['house'])]),\n",
      " Tree(Lemma('reaction.n.03.response'), [Tree('NN', ['response'])]),\n",
      " Tree(Lemma('person.n.01.person'), [Tree('NE', [Tree('NNP', ['Spahn'])])]),\n",
      " Tree(Lemma('future.n.01.future'), [Tree('NN', ['future'])]),\n",
      " Tree(Lemma('kiss.n.01.kiss'), [Tree('NN', ['kiss'])]),\n",
      " Tree('NNS', ['Thanks']),\n",
      " Tree(Lemma('possibility.n.01.possibility'), [Tree('NN', ['possibilities'])]),\n",
      " Tree(Lemma('person.n.01.person'), [Tree('NE', [Tree('NNP', ['Andruses'])])]),\n",
      " Tree(Lemma('person.n.01.person'), [Tree('NE', [Tree('NNP', ['Precious'])])]),\n",
      " Tree('NN', ['air']),\n",
      " Tree(Lemma('machine.n.01.machine'), [Tree('NN', ['machine'])]),\n",
      " Tree(Lemma('unit_cost.n.01.unit_cost'), [Tree('NN', ['unit', 'cost'])]),\n",
      " Tree(Lemma('plan.n.01.plan'), [Tree('NN', ['plan'])]),\n",
      " Tree(Lemma('motivation.n.01.need'), [Tree('NN', ['need'])]),\n",
      " Tree('NN', ['Addition']),\n",
      " Tree(Lemma('location.n.01.location'), [Tree('NE', [Tree('NNP', ['Sylvania'])])])]\n"
     ]
    }
   ],
   "source": [
    "nouns = get_nouns(random_sentences)\n",
    "pprint(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\andre\\Desktop\\Universit√†\\Magistrale\\TLN\\TLN-LAB\\nlp-UniTO-2021-22\\Radicioni\\es1B_wsd\\andrea_word_sense_disambiguation.ipynb Cella 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/andre/Desktop/Universit%C3%A0/Magistrale/TLN/TLN-LAB/nlp-UniTO-2021-22/Radicioni/es1B_wsd/andrea_word_sense_disambiguation.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m wn\u001b[39m.\u001b[39;49msynsets(\u001b[39m\"\u001b[39;49m\u001b[39mdog\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mlabel()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'label'"
     ]
    }
   ],
   "source": [
    "sent = tagged_sentences[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6847c98a8f86b01c6a19c518cd2f366693b80566b266804d5ca763cbb223f52b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
