{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercizio 3 - SemEval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consegna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Annotare** il file con i valori di similarità dati da noi e con i `BabelNetSynsetID` scelti da noi dal file `SemEval17_IT_senses2synsets.txt`.\n",
    "   \n",
    "2. **Agreement:** Dopo di che si calcola il `valore medio` di similarità, `Pearson` e `Spearman`\n",
    "   \n",
    "3. **Ricerca Automatica del Synset:** Andiamo a cercare il `BabelNetSynsetID` nel file dato dal prof `mini_NASARI.tsv`\n",
    "   andando a massimizzare la *cosine similarity*. I valori che massimizzeranno quest'ultima saranno i nostri concetti.\n",
    "\n",
    "   Per far ciò andiamo ad estrarre tutti i synsets relativi ad un termine, dal file `SemEval17_IT_senses2synsets.txt`\n",
    "   e andiamo a calcolare la *cosine similarity* per ogni synset (quelli dei due termini) presente nel file `mini_NASARI.tsv`\n",
    "   e salviamo i due sysnets che massimizzano la *cosine similarity*.\n",
    "\n",
    "   Facendo ciò otteniamo due synset, relativi ai termini, e un valore di similarità calcolato dal file NASARI.\n",
    "\n",
    "4. **Valutazione Similarità:** Sempre con `Pearson` e `Spearman`, tra i nostri valori di similarità e quelli trovati\n",
    "   al passo precedente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Associare i synset ai termini che pensiamo che massimizzino la similarità (fatto a mano) --> Gia fatto al passo 1 \n",
    "\n",
    "2. Output costituito da 6 campi: \n",
    "   1. Term1\n",
    "   2. Term2\n",
    "   3. BS1 (dato da noi)\n",
    "   4. BS2 (dato da noi)\n",
    "   5. Sinonimi Term1 (da synset a lemma)\n",
    "   6. Sinonimi Term2 (da synset a lemma)\n",
    "\n",
    "   <br/>     \n",
    "3. **Agreement dell'anotazione Synset trovati:** Tramite il punteggio `kappa di Cohen` calcoliamo il livello \n",
    "   di agreement (sklearn) tra i synset trovati da noi\n",
    "\n",
    "4. **Valutazione annotazione:** Confronto i nostri concetti (synset) con quelli che massimizzano la `cos_sim`\n",
    "   (Trovati già al passo 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a href=\"https://1drv.ms/x/s!AkdbdBkdl_1dhbcgYl1tXDNpjknAIw?e=UYsHF5\"> Link all'excel con i dati </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizzazione dei dati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andiamo a selezionare il dati da utilizzare per l'esercizio 3 tramite la funzione data dal professore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonicco        :\tcoppie nell'intervallo 51-100\n"
     ]
    }
   ],
   "source": [
    "def get_range(surname):\n",
    "    nof_elements = 500\n",
    "    base_idx = (abs(int(hashlib.sha512(surname.encode('utf-8')).hexdigest(), 16)) % 10)\n",
    "    idx_intervallo = base_idx * 50+1\n",
    "    return idx_intervallo\n",
    " \n",
    "\n",
    "input_name = \"Bonicco\"\n",
    "\n",
    "values = []\n",
    "sx = get_range(input_name)\n",
    "values.append(sx)\n",
    "dx = sx+50-1\n",
    "intervallo = \"\" + str(sx) + \"-\" + str(dx)\n",
    "print('{:15}:\\tcoppie nell\\'intervallo {}'.format(input_name, intervallo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiare il nome dell'annotatore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator = \"Bonicco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"../data/es3_res/it.test.data.txt\"\n",
    "data_file = \"SemEval_data_\" + annotator + \".tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['biotopo\\tbiologia', 'magma\\tvulcano', 'brainstorming\\ttelescopio', 'livello\\tpunteggio', 'centesimo\\taffare', 'partito politico\\tassociazione', 'tsunami\\tmare', 'struzzo\\tfrutteto', 'cannella\\tcaramella', 'scopa\\tpolvere', 'galassia\\tastronomo', 'succo\\tfrappè', 'tapparella\\ttenda', 'criminale\\tcolpevole', 'cancro al pancreas\\tchemioterapia', 'passato\\tantecedente', 'Nazioni Unite\\tParlamento Europeo', 'canzone\\tesecutore', 'pistola\\ttaccuino', 'acetilcolina\\tiride', 'alfabeto\\tpenna', 'coro\\tcantante', 'legno\\tcoperta', 'soldato\\tpace', 'inglese\\tamericano', 'lucertola\\tcoccodrillo', 'denaro\\tcontante', 'Polpo Paul\\tpolpo', 'calendario\\tvacanza', 'base\\tsostanza chimica', 'governo\\tlucertola', 'JPY\\triciclaggio di denaro', 'DeepMind\\tGoogle DeepMind', 'scacchi\\tscacco al re', 'sonetto\\tbellezza', 'lavoratore\\tufficio', 'valuta\\tscambio', 'poliestere\\tcotone', 'tribunale\\tgiustizia', 'coda\\tretro', 'incidente\\tlibro', 'groppo\\tvento', 'piano\\tarmonia', 'sultano\\tministero', 'deserto\\tduna', 'moltiplicazione\\tdivisione', 'virus\\tsangue', 'era glaciale\\tstatuto', 'spada\\tambiente', 'scuola elementare\\tpenna']\n"
     ]
    }
   ],
   "source": [
    "with open(path_data) as file:\n",
    "    lines = file.readlines()[50:100]\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "    print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open(data_file, 'w').close() # Puliamo il file con i termini di riferimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['biotopo', 'biologia']\n",
      "['magma', 'vulcano']\n",
      "['brainstorming', 'telescopio']\n",
      "['livello', 'punteggio']\n",
      "['centesimo', 'affare']\n",
      "['partito politico', 'associazione']\n",
      "['tsunami', 'mare']\n",
      "['struzzo', 'frutteto']\n",
      "['cannella', 'caramella']\n",
      "['scopa', 'polvere']\n",
      "['galassia', 'astronomo']\n",
      "['succo', 'frappè']\n",
      "['tapparella', 'tenda']\n",
      "['criminale', 'colpevole']\n",
      "['cancro al pancreas', 'chemioterapia']\n",
      "['passato', 'antecedente']\n",
      "['Nazioni Unite', 'Parlamento Europeo']\n",
      "['canzone', 'esecutore']\n",
      "['pistola', 'taccuino']\n",
      "['acetilcolina', 'iride']\n",
      "['alfabeto', 'penna']\n",
      "['coro', 'cantante']\n",
      "['legno', 'coperta']\n",
      "['soldato', 'pace']\n",
      "['inglese', 'americano']\n",
      "['lucertola', 'coccodrillo']\n",
      "['denaro', 'contante']\n",
      "['Polpo Paul', 'polpo']\n",
      "['calendario', 'vacanza']\n",
      "['base', 'sostanza chimica']\n",
      "['governo', 'lucertola']\n",
      "['JPY', 'riciclaggio di denaro']\n",
      "['DeepMind', 'Google DeepMind']\n",
      "['scacchi', 'scacco al re']\n",
      "['sonetto', 'bellezza']\n",
      "['lavoratore', 'ufficio']\n",
      "['valuta', 'scambio']\n",
      "['poliestere', 'cotone']\n",
      "['tribunale', 'giustizia']\n",
      "['coda', 'retro']\n",
      "['incidente', 'libro']\n",
      "['groppo', 'vento']\n",
      "['piano', 'armonia']\n",
      "['sultano', 'ministero']\n",
      "['deserto', 'duna']\n",
      "['moltiplicazione', 'divisione']\n",
      "['virus', 'sangue']\n",
      "['era glaciale', 'statuto']\n",
      "['spada', 'ambiente']\n",
      "['scuola elementare', 'penna']\n"
     ]
    }
   ],
   "source": [
    "terms_sim_score = []\n",
    "\n",
    "with open(data_file, 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    tsv_writer.writerow([\"Term1\", \"Term2\", \"Similarity\"])\n",
    "    \n",
    "    for tuple in lines:\n",
    "        w_couple = re.split(r'\\t+', tuple.rstrip('\\t'))\n",
    "        print(w_couple)\n",
    "        #! Scommentare per annotazione \"automatica\"\n",
    "        # score = input(\"\\tInserisci il valore di similarità [0 4] per i * \"+ str(w_couple) +\" *:\")\n",
    "        \n",
    "        tsv_writer.writerow(w_couple)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inizio Esercizio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venvradicioni': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe30bb084dadcc2974aabac99d8c6a813637b467837e0e94701709de5a097010"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
